{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7917641,"sourceType":"datasetVersion","datasetId":4652425},{"sourceId":7917645,"sourceType":"datasetVersion","datasetId":4652361},{"sourceId":7960452,"sourceType":"datasetVersion","datasetId":4682751}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Assignment Goals\n\nYour student ID:: 190042122\n\nThe goal of this assignment is to familiarize yourself with:\n\n1. Parsing HTML data\n2. Text classification using supervised machine learning algorithms\n3. Tools for sentiment analysis\n\nThe assignment combines tutorial components, with learning exercises that you must complete and submit. The learning exercise sections are clearly demarcated within the assignments.\n","metadata":{"id":"ISsm-4AF_HdW"}},{"cell_type":"markdown","source":"**Necessary Functions for the Assignment**","metadata":{"id":"ryTc6nJ4j521"}},{"cell_type":"code","source":"import requests\nimport nltk\nfrom nltk.util import ngrams\nimport requests\nimport time\nimport json\nimport math\nfrom pprint import pprint\n\n\n# Counts the frequency of token occurences in some text\ndef CountFrequency(my_list):\n\n    # Creating an empty dictionary\n    freq = {}\n    for item in my_list:\n        if (item in freq):\n            freq[item] += 1\n        else:\n            freq[item] = 1\n    return freq\n\n\n# An ngram extractor\n\ndef extract_word_ngrams(data, num):\n    n_grams = ngrams(nltk.word_tokenize(data), num)\n    return [ ' '.join(grams) for grams in n_grams]\n\n","metadata":{"id":"P2vPgbLA_HdX","execution":{"iopub.status.busy":"2024-03-29T18:00:43.559692Z","iopub.execute_input":"2024-03-29T18:00:43.560299Z","iopub.status.idle":"2024-03-29T18:00:46.253078Z","shell.execute_reply.started":"2024-03-29T18:00:43.560239Z","shell.execute_reply":"2024-03-29T18:00:46.251791Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"<hr>\n\n# Part 0: Collecting Data\n","metadata":{"id":"5165AZbF_HdY"}},{"cell_type":"markdown","source":"We will continue our journey through the text of the philosophers. More specifically, we'll be exploring how to use a natural language data for classification problems. To begin, let's return back to [Project Gutenburg](https://www.gutenberg.org/) and notice that the website not only provides us with access to the text of Bertrand's Russel's The Problem's of Philosophy, but also provides us with some interesting meta-data in the `Bibliographic Record` section.\n\n\n\n","metadata":{"id":"nAL5GtgK_HdZ"}},{"cell_type":"markdown","source":"Notice that the Bibliographic record provided by Project Gutenberg provides **classifications** of the books according their Library of Congress Class (`LOC Class`), as well as a `Subject`. Classifications are useful because they take our messy, continuous world and break it into manageable groupings that we can more easily act upon. Thanks to Project Gutenburg's classification, we can see that `The Problems of Philosophy` is a book about `Philosophy` (who would have guessed?!) and by knowing this classification we may (and most likely will) make some simplifying assumptions about the book without reading even a single line of it.\n\nIt would be useful if we could collect this Bibliographic record, in addition to the information in the raw text itself. But in order for us to extract that information, we'll first need to obtain some practice processing, and extracting information from, HTML documents. If this is your first time looking at HTML documents and you would like to review how they are formatted, you can use [W3 Schools](https://www.w3schools.com/html/default.asp).","metadata":{"id":"aIcNJ4iO_HdZ"}},{"cell_type":"markdown","source":"### Collecting and processing HTML data\nLet's start by looking through some simple HTML documents for a mythical social network that I've stored locally in this respository (`https://drive.google.com/drive/folders/1eUhKt26frIOQNiqXN9sxv68I9ZbA2Tge?usp=sharing`): [Anqa.html](https://drive.google.com/file/d/1Y08j9tqBoOTlPaAlIoyBJH33O77Fwq4r/view?usp=sharing), [Garuda.html](https://drive.google.com/file/d/1j18AuDUbhb9azL83g9CWuDxaBfbSP-sQ/view?usp=drive_link), [Konrul.html](https://drive.google.com/file/d/1E1nhxyCV6MUCpD8xe03AsvA_JPMpwpGB/view?usp=drive_link), [Nue.html](https://drive.google.com/file/d/1IGxkLbrzzhIbsxuWs7PVK9le-Ukk-6gI/view?usp=drive_link) and [Simargl.html](https://drive.google.com/file/d/1TN0Cn-OMbfZyurytUF3WLCa7YCD5Wq91/view?usp=drive_link). You will notice that each HTML file simply contains a list of friends and enemies with links to other webpages.\n\nTo help us obtain some familiarity with parsing these types of documents, let's see if we can write some code to rank order these five mysterious figures based on the number of friends and enemies that they have mentioned in their web pages. To be able to work with files, please download the html files first in your machine. Then create a folder called 'html' in the python environment you are working in and upload the html files in that folder. The first step in that process will be to read the HTML pages into Python:","metadata":{"id":"FkKeMPZ7_HdZ"}},{"cell_type":"code","source":"# A set of local HTML files\nhtml_files = ['Anqa.html','Garuda.html','Konrul.html','Nue.html','Simargl.html']\n\n# Read each file into a dictionary of HTML files\nhtml = {}\nfor file in html_files:\n    f = open('/kaggle/input/html-files-nlp/' + file, 'r');\n    html[file] = content = f.read();\n    f.close()","metadata":{"id":"vBqTX7LF_Hda","execution":{"iopub.status.busy":"2024-03-29T18:00:46.255032Z","iopub.execute_input":"2024-03-29T18:00:46.255551Z","iopub.status.idle":"2024-03-29T18:00:46.286872Z","shell.execute_reply.started":"2024-03-29T18:00:46.255518Z","shell.execute_reply":"2024-03-29T18:00:46.285326Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"<br><br>We now have a dictionary containing each of the HTML files. Here's Anqa.html:","metadata":{"id":"UYfECvKq_Hda"}},{"cell_type":"code","source":"print('\\n')\nprint(html['Anqa.html'])\nprint('\\n')","metadata":{"id":"RdbnkS-o_Hda","outputId":"5c008823-06bd-46aa-92ff-a0a3a48dd124","execution":{"iopub.status.busy":"2024-03-29T18:00:46.288617Z","iopub.execute_input":"2024-03-29T18:00:46.288994Z","iopub.status.idle":"2024-03-29T18:00:46.297834Z","shell.execute_reply.started":"2024-03-29T18:00:46.288962Z","shell.execute_reply":"2024-03-29T18:00:46.296187Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\n\n<html>\n<head><title>Anqa's Page</title></head>\n<body>\n\n<p class=\"friend\"> My friends are:\n<a href=\"/lab/tree/materials/html/Konrul.html\" class=\"best\"  id=\"link1\">Konrul</a> and\n</p>\n    \n<p class=\"enemy\"> My enemies are:\n<a href=\"/lab/tree/materials/html/Nue.html\"  class=\"worst\" id=\"link1\">Nue</a>.\n</p>\n\n</body>\n</html>\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<br> The trick to extracting information from HTML documents is to look for a unified structure across documents that your parser can take advantage of. If we inspect the raw HTML of all five documents, we'll notice that they each contain a `<p class=\"friend\">...</p>` and a `<p class=\"enemy\">...</p>` section and that within those sections there are multiple `<a>` tags that list out the names, and links to the pages of, friends and enemies. To extract this information we can use some carefully crafted Regular Expressions!","metadata":{"id":"-lGqDCN__Hdb"}},{"cell_type":"code","source":"import re\nfrom pprint import pprint\n\n# Function to extract the friendship data from an HTML page\ndef extractFriendData(html):\n    _data = {}\n\n    # Extract the friend and the enemy paragraphs:\n    p_friend = re.findall(r'<p[^>]*class=\"friend\"[^>]*>.*?</p>', html, re.DOTALL)[0]\n    p_enemy  = re.findall(r'<p[^>]*class=\"enemy\"[^>]*>.*?</p>' , html, re.DOTALL)[0]\n\n    # Within each paragraph, find the href\n    _data['friends'] = re.findall(r'>(Nue|Konrul|Garuda|Simargl|Anqa)<', p_friend, re.DOTALL)\n    _data['enemies'] = re.findall(r'>(Nue|Konrul|Garuda|Simargl|Anqa)<', p_enemy, re.DOTALL)\n\n    return _data\n\n# Run the function for each page, and store results in a dictionary\ndata = {}\nfor page in html.keys():\n    data[page.split('.')[0]] = extractFriendData(html[page])\n\nprint('\\n')\npprint(data)\nprint('\\n')","metadata":{"id":"chog9oCW_Hdb","outputId":"0698bff3-cccc-45f9-cd62-34eea534e299","execution":{"iopub.status.busy":"2024-03-29T18:00:46.301021Z","iopub.execute_input":"2024-03-29T18:00:46.301543Z","iopub.status.idle":"2024-03-29T18:00:46.314000Z","shell.execute_reply.started":"2024-03-29T18:00:46.301500Z","shell.execute_reply":"2024-03-29T18:00:46.312819Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"\n\n{'Anqa': {'enemies': ['Nue'], 'friends': ['Konrul']},\n 'Garuda': {'enemies': ['Konrul'], 'friends': ['Anqa', 'Konrul']},\n 'Konrul': {'enemies': ['Anqa'], 'friends': ['Nue']},\n 'Nue': {'enemies': [], 'friends': ['Simargl', 'Nue']},\n 'Simargl': {'enemies': ['Nue'], 'friends': []}}\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<br>Using the code block above, we are able to extract the structured data from the set of HTML documents. From here, it won't take much work to understand who has the most friends, and who has the most enemies in our mythical social network:\n","metadata":{"id":"HvWVxagl_Hdb"}},{"cell_type":"code","source":"friends, enemies = [], []\nfor page in data:\n    friends += data[page]['friends']\n    enemies += data[page]['enemies']\n\nprint('Friendship counts:'); pprint(CountFrequency(friends)); print('\\n')\nprint('Enemy counts:'); pprint(CountFrequency(enemies)); print('\\n')","metadata":{"id":"blN3lBj6_Hdb","outputId":"f3af1d2c-f213-4d8b-e233-fa5f98c0e6a5","execution":{"iopub.status.busy":"2024-03-29T18:00:46.315498Z","iopub.execute_input":"2024-03-29T18:00:46.316852Z","iopub.status.idle":"2024-03-29T18:00:46.328132Z","shell.execute_reply.started":"2024-03-29T18:00:46.316799Z","shell.execute_reply":"2024-03-29T18:00:46.326578Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Friendship counts:\n{'Anqa': 1, 'Konrul': 2, 'Nue': 2, 'Simargl': 1}\n\n\nEnemy counts:\n{'Anqa': 1, 'Konrul': 1, 'Nue': 2}\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Text classification using supervised machine learning algorithms","metadata":{"id":"nSUc-wBUofQr"}},{"cell_type":"markdown","source":"<br> In this part of the assignment, we will import 4 books: 2 of Bertrand Russel and 2 of Friedrich Nietzsche. The books are available in this link: (`https://drive.google.com/drive/folders/1fMLxidEOXiaSCTU7fAAdzj3rvyNfe7Tv?usp=sharing`). Please download all these 4 books and upload it in your environment creating a folder named 'books_json'.","metadata":{"id":"-P3s_TDa_Hdb"}},{"cell_type":"markdown","source":"<br><br> Let's take a peak at the data in `Beyond_Good_and_Evil.json`:","metadata":{"id":"SPT6KTPm_Hdc"}},{"cell_type":"code","source":"import json\n# Open the book\nwith open('/kaggle/input/books-json/Beyond_Good_and_Evil.json',encoding='utf-8') as f:\n    book = json.loads(f.read())\n\nprint('------------------------------------------------------------')\nprint('Subject   - '   + ''.join(book['Title'])  +\n      '\\nBy        - ' + ''.join(book['Author']) +\n      '\\nLoC Class - ' + ';'.join(book['LoC Class']))\nprint('------------------------------------------------------------')\nprint('**Sample Text**:' + book['text'][11012:11508] + '...')","metadata":{"id":"YUMXiqfM_Hdc","outputId":"52939e8d-6472-477f-e844-5486fcb22602","execution":{"iopub.status.busy":"2024-03-29T18:00:46.330697Z","iopub.execute_input":"2024-03-29T18:00:46.331223Z","iopub.status.idle":"2024-03-29T18:00:46.356248Z","shell.execute_reply.started":"2024-03-29T18:00:46.331162Z","shell.execute_reply":"2024-03-29T18:00:46.355023Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"------------------------------------------------------------\nSubject   - Beyond Good and Evil\nBy        - Nietzsche, Friedrich Wilhelm, 1844-1900\nLoC Class - B: Philosophy, Psychology, Religion\n------------------------------------------------------------\n**Sample Text**:r part of the\nconscious thinking of a philosopher is secretly influenced by his\ninstincts, and forced into definite channels. And behind all logic and\nits seeming sovereignty of movement, there are valuations, or to speak\nmore plainly, physiological demands, for the maintenance of a definite\nmode of life For example, that the certain is worth more than the\nuncertain, that illusion is less valuable than \"truth\" such valuations,\nin spite of their regulative importance for US, might notw...\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<br><br> Now let's separate the data by author into two corpora, one for `Nietzsche` and one for `Russel` and perform some basic cleaning on the text by removing non-ascii characters, and converting everything to lowercase.","metadata":{"id":"uTwPdvpZ_Hdd"}},{"cell_type":"code","source":"import re\nfrom os import listdir\nimport json\n# -----------------------------------------------\n# Import the books\n# -----------------------------------------------\nbooks = listdir('/kaggle/input/books-json/')\nfiles = ['/kaggle/input/books-json/' + book for book in books if book[0] != '.']\n\ndata = []\nfor file in files:\n    with open(file) as f:\n        x = json.load(f)\n        data.append(x)\n# -----------------------------------------------\n# Merge the text from Nietzsche and Russel into two corpora\n# -----------------------------------------------\nNietzsche, Russel = '', ''\nfor item in data:\n    if 'Nietzsche' in item['Author'][0]:\n        Nietzsche  += item['text'].replace(u'\\xa0', u' ').replace(u'\\ufeff', u' ').replace('_', ' ') + ' '\n    if 'Russel'    in item['Author'][0]:\n        Russel     += item['text'].replace(u'\\xa0', u' ').replace(u'\\ufeff', u' ').replace('_', ' ') + ' '\n\n# -----------------------------------------------\n# Keeping only the ascii charaacters\n# -----------------------------------------------\nNietzsche = re.sub(r'[^\\x00-\\x7F]+','', Nietzsche)\nRussel    = re.sub(r'[^\\x00-\\x7F]+','', Russel)\n\n# -----------------------------------------------\n# Converting all words to lower case\n# -----------------------------------------------\nNietzsche  = Nietzsche.lower()\nRussel     = Russel.lower()\n\n# print(Nietzsche)","metadata":{"id":"SfgJtvwL_Hdd","execution":{"iopub.status.busy":"2024-03-29T18:00:46.357825Z","iopub.execute_input":"2024-03-29T18:00:46.359705Z","iopub.status.idle":"2024-03-29T18:00:46.449983Z","shell.execute_reply.started":"2024-03-29T18:00:46.359622Z","shell.execute_reply":"2024-03-29T18:00:46.448971Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"<hr>\n\n# Part 1: Classification using Classification Models\nLanguage models can be used for classification purposes by comparing the probability that a given sequence of text was generated by one author, versus another. But if our objective is to classify the author of a text, we need not spend so much time building a language model; instead we can focus our attention on the classification task directly.\n\nLet's return to the earlier task of sentence classification, starting with breaking our corpora into sentences.","metadata":{"id":"BBl1D0iL_Hdr"}},{"cell_type":"code","source":"import nltk\nnltk.download('punkt')\n\nr_sentences = nltk.sent_tokenize(Russel)\nn_sentences = nltk.sent_tokenize(Nietzsche)\n\nprint('Sentences in Nietzsche Books: ', len(n_sentences))\nprint('Sentences in Russel Books:    ', len(r_sentences))\n\nprint('------------------------------------------')\nprint('Here is an example sentence from Russel:')\nprint('------------------------------------------')\nprint(r_sentences[152])","metadata":{"id":"2BOFPUHE_Hdr","outputId":"7fceffa8-b502-4893-e9b0-3ce1f0467029","execution":{"iopub.status.busy":"2024-03-29T18:00:46.451773Z","iopub.execute_input":"2024-03-29T18:00:46.452729Z","iopub.status.idle":"2024-03-29T18:00:47.160944Z","shell.execute_reply.started":"2024-03-29T18:00:46.452685Z","shell.execute_reply":"2024-03-29T18:00:47.159342Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\nSentences in Nietzsche Books:  3099\nSentences in Russel Books:     3113\n------------------------------------------\nHere is an example sentence from Russel:\n------------------------------------------\nin this there is no opposition to instinct as a\nwhole, but only to blind reliance upon some one interesting aspect of\ninstinct to the exclusion of other more commonplace but not less\ntrustworthy aspects.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Bag of Words\nAs we discussed in the lectures, a bag-of-words is a simple way of representing a text document or segment as the count of the n-grams within it. With that in mind, let's convert the example sentence above into a bag-of-words representation:","metadata":{"id":"3OfAW5nI_Hdr"}},{"cell_type":"code","source":"unigram     = extract_word_ngrams(r_sentences[152],1)\nbag_of_word = CountFrequency(unigram)\n\npprint(bag_of_word)","metadata":{"id":"wpQrBa-m_Hdr","outputId":"4107ff4a-768d-4e36-82f4-eec3a7dac044","execution":{"iopub.status.busy":"2024-03-29T18:00:47.162811Z","iopub.execute_input":"2024-03-29T18:00:47.163196Z","iopub.status.idle":"2024-03-29T18:00:47.173805Z","shell.execute_reply.started":"2024-03-29T18:00:47.163166Z","shell.execute_reply":"2024-03-29T18:00:47.171962Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"{',': 1,\n '.': 1,\n 'a': 1,\n 'as': 1,\n 'aspect': 1,\n 'aspects': 1,\n 'blind': 1,\n 'but': 2,\n 'commonplace': 1,\n 'exclusion': 1,\n 'in': 1,\n 'instinct': 2,\n 'interesting': 1,\n 'is': 1,\n 'less': 1,\n 'more': 1,\n 'no': 1,\n 'not': 1,\n 'of': 2,\n 'one': 1,\n 'only': 1,\n 'opposition': 1,\n 'other': 1,\n 'reliance': 1,\n 'some': 1,\n 'the': 1,\n 'there': 1,\n 'this': 1,\n 'to': 3,\n 'trustworthy': 1,\n 'upon': 1,\n 'whole': 1}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<br><br> Notice that converting a sentence to its bag-of-words representation eliminates information about the order of the words! That is, if I simply provided you this bag of words, you would have no way of (consistently) reconstructing the original sentence that was used to generate it. So why would anyone use a bag-of-words representation? Because it provides a simple way to convert our sentences into numerical vectors, for instance:","metadata":{"id":"TpfX1C4B_Hdr"}},{"cell_type":"code","source":"vector = list(bag_of_word.values())\nprint(vector)","metadata":{"id":"0fjtyfva_Hdr","outputId":"e0d8c212-4de5-435b-cba6-da82cbb2c95f","execution":{"iopub.status.busy":"2024-03-29T18:00:47.179087Z","iopub.execute_input":"2024-03-29T18:00:47.179481Z","iopub.status.idle":"2024-03-29T18:00:47.187809Z","shell.execute_reply.started":"2024-03-29T18:00:47.179446Z","shell.execute_reply":"2024-03-29T18:00:47.186061Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"[1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<br><br>Once we have transformed a string into a numerical vector, we can treat language like we would any other numerical object! That is, having all of our sentences represented as points in a vector space will allow us to do things like train models that can classify the authors of documents!\n\nBut before we dive into classification using these vectors, we'll need to address a deficiency of the bag of words representation shown in the above example. Consider the fact that any given sentence is likely to only contain a small number of the total words in a given vocabulary. Consequently, if we want to compare two vectors, we'll need to keep track of both the words from the vocabulary that showed up, as well as those that did not! Here's how:","metadata":{"id":"qjcu7-BH_Hds"}},{"cell_type":"code","source":"# Get all the distinct unigrams from the Russel books and the Nietzsche books and combine them\nvocabulary    = list(set( extract_word_ngrams(Russel, 1) + extract_word_ngrams(Nietzsche, 1) ))\n\n# Get the sentence I want to cast as bag of words:\nunigram = extract_word_ngrams(r_sentences[152],1)\n\n# Convert to bag of words:\ntainted_bow  = CountFrequency(unigram + vocabulary)         # append the vocabulary to make sure it's counted\nbag_of_words = {k: v - 1 for k, v in tainted_bow.items()}         # remove the counts that came from the vocabulary\nvector       = list(bag_of_words.values())                        # cast to a vector","metadata":{"id":"0Z_cq__O_Hds","execution":{"iopub.status.busy":"2024-03-29T18:00:47.189513Z","iopub.execute_input":"2024-03-29T18:00:47.190068Z","iopub.status.idle":"2024-03-29T18:00:49.948396Z","shell.execute_reply.started":"2024-03-29T18:00:47.190037Z","shell.execute_reply":"2024-03-29T18:00:49.946996Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print('Bag of Words representation (showing first 50 entries, only):')\nprint(vector[0:50])","metadata":{"id":"GnXBcda6_Hds","outputId":"dd03d5d9-7dd6-4abe-9905-a95a5baaf814","execution":{"iopub.status.busy":"2024-03-29T18:00:49.949778Z","iopub.execute_input":"2024-03-29T18:00:49.950394Z","iopub.status.idle":"2024-03-29T18:00:49.956748Z","shell.execute_reply.started":"2024-03-29T18:00:49.950360Z","shell.execute_reply":"2024-03-29T18:00:49.955297Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Bag of Words representation (showing first 50 entries, only):\n[1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<br><br>The above code is not the most computationally efficient way to create the bag of words representation, but it's useful to help you understand exactly what a bag-of-words representation is capturing, and how it is generated. In reality, we would want to store our bag of words representation of the text in a sparse array instead of a memory-inefficient dictionary or list. Fortunately, there are Python packages that take care of creating bag-of-words representations in only a few lines of code. Let's use the [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) function within Python's [Sklearn Library](https://scikit-learn.org/stable/) to convert the sentences we extracted earlier into their bag-of-words represenations:","metadata":{"id":"TbiFevdo_Hds"}},{"cell_type":"code","source":"import numpy as np\n\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# Generate an array that casts the language to a bag of words representation:\nvectorizer = CountVectorizer()\nX          = vectorizer.fit_transform(r_sentences + n_sentences)\nX          = X.toarray()\n\n\nprint('Bag of words representation for', len(r_sentences), 'Russel sentences and', len(n_sentences), 'Nietzsche sentences')\nprint('Yields a array, X of size:',np.size(X,0), 'sentences x', np.size(X,1), 'tokens')\nprint(X)","metadata":{"id":"R9xVqmsn_Hds","outputId":"d708591e-fb41-4ef8-b9a1-197a144507d0","execution":{"iopub.status.busy":"2024-03-29T18:00:49.958614Z","iopub.execute_input":"2024-03-29T18:00:49.958949Z","iopub.status.idle":"2024-03-29T18:00:50.559316Z","shell.execute_reply.started":"2024-03-29T18:00:49.958921Z","shell.execute_reply":"2024-03-29T18:00:50.557822Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Bag of words representation for 3113 Russel sentences and 3099 Nietzsche sentences\nYields a array, X of size: 6212 sentences x 12937 tokens\n[[0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n ...\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<br><br>Note that the `CountVectorizer` object operates on the sentences themselves, performs the tokenization, and can even compute the representation for various n-gram sizes by setting `ngram_range` value of the function.\n\nNow that we have a numerical representation of our text, we can start training machine learning algorithms with it. Recall from the lecture that supervised classification methods help our models learn a mathematical transformation of some given data, such as the words in a sentence, into some other data that we would like to make predictions about, such as the author of the sentence. We already created a numerical representation of the text, so all we need now is a numerical representation of the authors:","metadata":{"id":"-wN3-smd_Hds"}},{"cell_type":"code","source":"import numpy as np\n\ny = np.asarray([1 for i in range(0,len(r_sentences))] + [0 for i in range(0,len(n_sentences))])\nprint(y)\nprint(np.size(y))","metadata":{"id":"P28i7mDV_Hds","execution":{"iopub.status.busy":"2024-03-29T18:00:50.561156Z","iopub.execute_input":"2024-03-29T18:00:50.562132Z","iopub.status.idle":"2024-03-29T18:00:50.573701Z","shell.execute_reply.started":"2024-03-29T18:00:50.562087Z","shell.execute_reply":"2024-03-29T18:00:50.572596Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"[1 1 1 ... 0 0 0]\n6212\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<hr>\n\n# Learning Exercise 3:\n### Worth 2/5 Points\nAs we discussed in the lectures, Naive bayes refers to a simple probabilistic classifier based on Bayes' theorem, with some strong independence assumptions about the conditional relationships between features. For this learning exercise you will explore the properties of Naive Bayes, and a few other classification models, given a bag of words representation of the text.","metadata":{"id":"sMooNXkH_Hds"}},{"cell_type":"markdown","source":"#### A. Train and Assess a Naive Bayes Model\nThe code block below trains a Naive Bayes Model on 80% of the data from the tutorial, and tests the model on the remaining 20%. Please study and extend the code block provided below to:\n\n1. Use bi-grams instead of unigrams as the \"words\" in the bag of words model\n3. Perform 10-fold cross validation instead of an 80% - 20% validation\n2. Report the mean and standard deviation of the following performance metrics across the ten validation folds:\n    * accuracy, precision, recall, f1-score (micro & macro) and area under the reciever operator curve\n\n**PLEASE NOTE:** You must compute the accuracy, precision, recall, and area under the ROC curve using functions you write yourself, not functions from `sklearn`","metadata":{"id":"iSZ2UCnc_Hdt"}},{"cell_type":"code","source":"from sklearn.naive_bayes     import MultinomialNB\nfrom sklearn.model_selection import train_test_split,StratifiedKFold\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport numpy as np\n\n\n# Split the data into training (80%) and testing (20%) sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n\n# initialize a Nieve bayes model\nnaive      = MultinomialNB()\n\n# Fit the model using the training data\nclassifier = naive.fit(X_train,y_train)\n\n# predict the author of the held-out test sentences\npredict    = classifier.predict(X_test)\n\n# generate the confusion matrix\ncm         = confusion_matrix(y_test, predict)\ntn, fp, fn, tp = cm.ravel()\n\n# print the confusion matrix components\nprint('True Positives: ',  tp)\nprint('False Positives:',  fp)\nprint('True Negatives: ',  tn)\nprint('False Negatives:',  fn)\nprint('------------------------')\n################################################################################\n# INSERT YOUR CODE HERE\n# DO NOT FORGET TO PRINT YOUR MEANINGFUL RESULTS TO THE SCREEN.\n################################################################################\n\n# Function to compute accuracy\ndef compute_accuracy(y_true, y_pred):\n    return np.mean(y_true == y_pred)\n\n# Function to compute precision\ndef compute_precision(y_true, y_pred):\n    tp = np.sum((y_true == 1) & (y_pred == 1))\n    fp = np.sum((y_true == 0) & (y_pred == 1))\n    return tp / (tp + fp)\n\n# Function to compute recall\ndef compute_recall(y_true, y_pred):\n    tp = np.sum((y_true == 1) & (y_pred == 1))\n    fn = np.sum((y_true == 1) & (y_pred == 0))\n    return tp / (tp + fn)\n\n# Function to compute F1-score\ndef compute_f1_score(y_true, y_pred):\n    precision = compute_precision(y_true, y_pred)\n    recall = compute_recall(y_true, y_pred)\n    return 2 * (precision * recall) / (precision + recall)\n\n# Function to compute AUC\ndef compute_auc(y_true, y_prob):\n    fpr, tpr, thresholds = roc_curve(y_true, y_prob, pos_label=1)\n    return auc(fpr, tpr)\n\n# Initialize CountVectorizer with bigrams\nvectorizer = CountVectorizer(ngram_range=(2, 2))\nX = vectorizer.fit_transform(r_sentences + n_sentences).toarray()\n\n# Initialize KFold with 10 folds\nkf = StratifiedKFold(n_splits=10, shuffle=True, random_state=123)\n\naccuracy_scores = []\nprecision_scores = []\nrecall_scores = []\nf1_scores_micro = []\nf1_scores_macro = []\nauc_scores = []\n\n# Perform 10-fold cross-validation\nfor train_index, test_index in kf.split(X, y):\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n\n    # Initialize a Naive Bayes model\n    naive = MultinomialNB()\n\n    # Fit the model using the training data\n    classifier = naive.fit(X_train, y_train)\n\n    # Predict the probabilities of classes for the test data\n    y_prob = classifier.predict_proba(X_test)[:, 1]\n\n    # Predict the author of the held-out test sentences\n    y_pred = classifier.predict(X_test)\n\n    # Compute performance metrics\n    accuracy_scores.append(compute_accuracy(y_test, y_pred))\n    precision_scores.append(compute_precision(y_test, y_pred))\n    recall_scores.append(compute_recall(y_test, y_pred))\n    f1_scores_micro.append(compute_f1_score(y_test, y_pred))\n    f1_scores_macro.append(compute_f1_score(y_test, y_pred))\n    auc_scores.append(compute_auc(y_test, y_prob))\n\n    # Generate the confusion matrix\n    cm = confusion_matrix(y_test, y_pred)\n    tn, fp, fn, tp = cm.ravel()\n\n\n# Print the mean and standard deviation of performance metrics\nprint(\"\\nMean and Standard Deviation of Performance Metrics Across Folds:\")\nprint(\"Accuracy (mean):\", np.mean(accuracy_scores))\nprint(\"Precision (mean):\", np.mean(precision_scores))\nprint(\"Recall (mean):\", np.mean(recall_scores))\nprint(\"F1-score (micro, mean):\", np.mean(f1_scores_micro))\nprint(\"F1-score (macro, mean):\", np.mean(f1_scores_macro))\nprint(\"AUC (mean):\", np.mean(auc_scores))","metadata":{"id":"Yv8FP6rQ_Hdt","outputId":"b11a3d0c-cc27-46f0-e54f-1359fdd57071","execution":{"iopub.status.busy":"2024-03-29T18:00:50.575175Z","iopub.execute_input":"2024-03-29T18:00:50.575716Z","iopub.status.idle":"2024-03-29T18:01:53.328014Z","shell.execute_reply.started":"2024-03-29T18:00:50.575685Z","shell.execute_reply":"2024-03-29T18:01:53.326854Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"True Positives:  574\nFalse Positives: 98\nTrue Negatives:  500\nFalse Negatives: 71\n------------------------\n\nMean and Standard Deviation of Performance Metrics Across Folds:\nAccuracy (mean): 0.8063462106031658\nPrecision (mean): 0.7576972917330342\nRecall (mean): 0.9026681919366807\nF1-score (micro, mean): 0.8237368996858887\nF1-score (macro, mean): 0.8237368996858887\nAUC (mean): 0.8952731996341466\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<span style=\"color:red\"> COMMENT ON YOUR RESULTS.</span>","metadata":{"id":"TVTPkz1T_Hdt"}},{"cell_type":"markdown","source":"Based on the accuracy score;\nI think that the majority of predictions made by the model are correct across all folds. The model achieved an average accuracy of approximately 80.63%. \n\nBased on the Precision score;\nWith an average precision of about 75.77%, the model correctly identified positive instances among all instances predicted as positive. This metric is crucial for scenarios where minimizing false positives is important.\n\nBased on the Recall value;\nThe mean recall of around 90.27% indicates the model's effectiveness in capturing all relevant instances, particularly positive ones, from the entire dataset. A higher recall value suggests that the model is successful in identifying most positive instances.\n\nF1-score (micro, mean):\nThe micro-average F1-score, averaging approximately 82.37%, provides an overall assessment of the model's performance across all classes by considering the harmonic mean of precision and recall. It's particularly useful for evaluating imbalanced datasets.\n\nF1-score (macro, mean):\nSimilarly, the macro-average F1-score also averages around 82.37%, but it treats all classes equally without considering class imbalances.\n\nAUC (mean):\nThe mean Area Under the ROC Curve (AUC) of about 89.53% reflects the model's ability to differentiate between positive and negative instances across all folds. A higher AUC value indicates better discrimination performance, suggesting that the model effectively ranks instances.","metadata":{}},{"cell_type":"markdown","source":"#### B. Construct a dataset that highlights the limitations of Naive Bayes\nConstruct an example dataset of 10-20 sentences that highlights how the feature independence assumptions of Naive Bayes can lead to poor performance. Train Naive Bayes using the dataset you construct and comment on your results.","metadata":{"id":"lPCqLdV8_Hdt"}},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# Dataset\nsentences = [\n    # Sentences from Author A\n    \"The movie was incredibly thrilling and kept me on the edge of my seat.\",\n    \"I absolutely loved the characters and their development throughout the story.\",\n    \"The cinematography in this film is breathtaking, truly a visual masterpiece.\",\n    \"This movie is a must-watch for any film enthusiast.\",\n    \"The director's vision shines through in every frame.\",\n    \n    # Sentences from Author B\n    \"I couldn't stand this movie, it was boring and predictable.\",\n    \"The acting was atrocious, I couldn't believe how wooden the performances were.\",\n    \"This film was a complete waste of time and money.\",\n    \"The plot lacked depth and failed to engage me.\",\n    \"I found myself checking my watch constantly, waiting for the movie to end.\",\n    \n    # Sentences from Author C\n    \"I have mixed feelings about this movie, some parts were good but others fell flat.\",\n    \"The plot was interesting but the pacing was off, it felt disjointed.\",\n    \"While the acting was decent, the dialogue felt forced and unnatural.\",\n    \"I appreciated the attempt at something different but it didn't quite land.\",\n    \"There were moments of brilliance, but overall it fell short of my expectations.\"\n]\n\n# Labels for each sentence\nlabels = ['Author A', 'Author A', 'Author A', 'Author A', 'Author A',\n          'Author B', 'Author B', 'Author B', 'Author B', 'Author B',\n          'Author C', 'Author C', 'Author C', 'Author C', 'Author C']\n\n# Convert text data into bag-of-words representation\nvectorizer = CountVectorizer()\nX_New = vectorizer.fit_transform(sentences).toarray()\n\n# Train Naive Bayes classifier\nnaive_bayes = MultinomialNB()\nnaive_bayes.fit(X_New, labels)\n\n# Test predictions\ntest_sentences = [\n    \"I loved the movie, it was so engaging.\",\n    \"The acting was terrible, I couldn't believe how bad it was.\", \n    \"The plot was intriguing but the execution fell short.\",  \n    \"The characters were unforgettable, they really brought the story to life.\",\n    \"This film was amazing, I was hooked from start to finish.\",\n    \"The cinematography was breathtaking, I couldn't take my eyes off the screen.\",\n    \"The pacing was perfect and kept me engaged throughout the entire movie.\",\n    \"The plot twists were unexpected and kept me guessing until the end.\",\n    \"I found the dialogue to be witty and well-written.\",\n    \"The character development was lacking and left me feeling disconnected from the story.\"\n]\n\n# Labels for test sentences\ntrue_labels = ['Author A', 'Author B', 'Author C', 'Author B', 'Author C',\n               'Author A', 'Author A', 'Author A', 'Author A', 'Author B']\n\nX_New_test = vectorizer.transform(test_sentences)\npredictions = naive_bayes.predict(X_New_test)\n\n# Print predictions with predicted author\nfor sentence, prediction, true_label in zip(test_sentences, predictions, true_labels):\n    print(f\"Sentence: '{sentence}' - Predicted author: {prediction}, True author: {true_label}\")\n\n# Calculate accuracy\naccuracy = sum(1 for true_label, prediction in zip(true_labels, predictions) if true_label == prediction) / len(true_labels)\n\n# Print accuracy\nprint(\"\\nAccuracy:\", accuracy)\n","metadata":{"id":"NupJpv4V_Hdt","execution":{"iopub.status.busy":"2024-03-29T18:01:53.329830Z","iopub.execute_input":"2024-03-29T18:01:53.330686Z","iopub.status.idle":"2024-03-29T18:01:53.377710Z","shell.execute_reply.started":"2024-03-29T18:01:53.330641Z","shell.execute_reply":"2024-03-29T18:01:53.376477Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Sentence: 'I loved the movie, it was so engaging.' - Predicted author: Author C, True author: Author A\nSentence: 'The acting was terrible, I couldn't believe how bad it was.' - Predicted author: Author B, True author: Author B\nSentence: 'The plot was intriguing but the execution fell short.' - Predicted author: Author C, True author: Author C\nSentence: 'The characters were unforgettable, they really brought the story to life.' - Predicted author: Author A, True author: Author B\nSentence: 'This film was amazing, I was hooked from start to finish.' - Predicted author: Author B, True author: Author C\nSentence: 'The cinematography was breathtaking, I couldn't take my eyes off the screen.' - Predicted author: Author A, True author: Author A\nSentence: 'The pacing was perfect and kept me engaged throughout the entire movie.' - Predicted author: Author A, True author: Author A\nSentence: 'The plot twists were unexpected and kept me guessing until the end.' - Predicted author: Author B, True author: Author A\nSentence: 'I found the dialogue to be witty and well-written.' - Predicted author: Author B, True author: Author A\nSentence: 'The character development was lacking and left me feeling disconnected from the story.' - Predicted author: Author A, True author: Author B\n\nAccuracy: 0.4\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### B. Construct a dataset that highlights how negation can be handled in  Naive Bayes\nA very simple baseline that is commonly used in sentiment analysis to deal with negation is the following: during text normalization, prepend the prefix NOT to every word after a token of logical negation (n’t, not, no, never) until the next punctuation mark. Thus the phrase\n\n      didn’t like this movie , but I\n\nbecomes\n\n      didn’t NOT_like NOT_this NOT_movie , but I\n\nConstruct an example dataset of 10-20 sentences that highlights how you would handle negation in Naive Bayes. Train Naive Bayes ***with*** and ***without*** your method with the dataset you construct and compare the differences on your results.","metadata":{"id":"IEReBIgZXd7m"}},{"cell_type":"code","source":"################################################################################\n# INSERT YOUR CODE HERE\n# DO NOT FORGET TO PRINT YOUR MEANINGFUL RESULTS TO THE SCREEN.\n################################################################################\n\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# Original sentences with negation\noriginal_sentences = [\n    \"I didn't like this movie, but I enjoyed the acting.\",\n    \"The food wasn't great, but the service was excellent.\",\n    \"She never said anything rude to me.\",\n    \"He doesn't have any bad intentions.\",\n    \"They haven't been to this restaurant before.\",\n    \"I didn't find the book interesting, but the ending surprised me.\",\n    \"The weather wasn't nice, but the company was enjoyable.\",\n    \"I never doubted his sincerity.\",\n    \"They don't lack ambition, they lack direction.\",\n    \"She hasn't failed us before.\"\n]\n\n# Modified sentences with negation handling\nmodified_sentences = [\n    \"I didn't NOT_like NOT_this NOT_movie , but I enjoyed the acting.\",\n    \"The food wasn't NOT_great , but the service was excellent.\",\n    \"She never NOT_said NOT_anything NOT_rude to me.\",\n    \"He doesn't NOT_have NOT_any NOT_bad NOT_intentions.\",\n    \"They haven't NOT_been NOT_to NOT_this NOT_restaurant NOT_before.\",\n    \"I didn't NOT_find NOT_the NOT_book NOT_interesting , but the ending surprised me.\",\n    \"The weather wasn't NOT_nice , but the company was enjoyable.\",\n    \"I never NOT_doubted NOT_his NOT_sincerity.\",\n    \"They don't NOT_lack NOT_ambition , they lack direction.\",\n    \"She hasn't NOT_failed NOT_us NOT_before.\"\n]\n\n# Labels for each sentence\nlabels = ['negative', 'negative', 'positive', 'positive', 'positive',\n          'negative', 'negative', 'positive', 'positive', 'positive']\n\n# Convert text data into bag-of-words representation for both original and modified sentences\nvectorizer = CountVectorizer()\nX_original = vectorizer.fit_transform(original_sentences).toarray()\nX_modified = vectorizer.transform(modified_sentences).toarray()\n\n# Train Naive Bayes classifier without negation handling\nnaive_bayes_original = MultinomialNB()\nnaive_bayes_original.fit(X_original, labels)\n\n# Train Naive Bayes classifier with negation handling\nnaive_bayes_modified = MultinomialNB()\nnaive_bayes_modified.fit(X_modified, labels)\n\n# Test predictions\ntest_sentences = [\n    \"I liked this movie, but I didn't enjoy the acting.\",\n    \"The food was great, but it wasn't excellent.\",\n    \"She said something rude to me.\",\n    \"He has some bad intentions.\",\n    \"They have been to this restaurant before.\",\n]\n\n# Test labels\ntrue_labels = ['negative', 'positive', 'negative', 'positive', 'positive']\n\n\n# Convert test sentences into bag-of-words representation\nX_Neg_test = vectorizer.transform(test_sentences).toarray()\n","metadata":{"id":"DKKsH0ufYgf8","execution":{"iopub.status.busy":"2024-03-29T18:01:53.379577Z","iopub.execute_input":"2024-03-29T18:01:53.380349Z","iopub.status.idle":"2024-03-29T18:01:53.409414Z","shell.execute_reply.started":"2024-03-29T18:01:53.380306Z","shell.execute_reply":"2024-03-29T18:01:53.407596Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n# Predictions without negation handling\npredictions_original = naive_bayes_original.predict(X_Neg_test)\n\n# Predictions with negation handling\npredictions_modified = naive_bayes_modified.predict(X_Neg_test)\n\n# Print predictions\nprint(\"Predictions without negation handling:\")\nfor sentence, prediction in zip(test_sentences, predictions_original):\n    print(f\"Sentence: '{sentence}' - Predicted sentiment: {prediction}\")\n\nprint(\"\\nPredictions with negation handling:\")\nfor sentence, prediction in zip(test_sentences, predictions_modified):\n    print(f\"Sentence: '{sentence}' - Predicted sentiment: {prediction}\")\n\n# Calculate accuracy score\naccuracy_original = accuracy_score(true_labels, predictions_original)\naccuracy_modified = accuracy_score(true_labels, predictions_modified)\n\n# Print accuracy score\nprint(\"\\nAccuracy without negation handling:\", accuracy_original)\nprint(\"Accuracy with negation handling:\", accuracy_modified)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-29T18:01:53.411572Z","iopub.execute_input":"2024-03-29T18:01:53.412322Z","iopub.status.idle":"2024-03-29T18:01:53.433890Z","shell.execute_reply.started":"2024-03-29T18:01:53.412280Z","shell.execute_reply":"2024-03-29T18:01:53.431197Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Predictions without negation handling:\nSentence: 'I liked this movie, but I didn't enjoy the acting.' - Predicted sentiment: negative\nSentence: 'The food was great, but it wasn't excellent.' - Predicted sentiment: negative\nSentence: 'She said something rude to me.' - Predicted sentiment: positive\nSentence: 'He has some bad intentions.' - Predicted sentiment: positive\nSentence: 'They have been to this restaurant before.' - Predicted sentiment: positive\n\nPredictions with negation handling:\nSentence: 'I liked this movie, but I didn't enjoy the acting.' - Predicted sentiment: negative\nSentence: 'The food was great, but it wasn't excellent.' - Predicted sentiment: negative\nSentence: 'She said something rude to me.' - Predicted sentiment: positive\nSentence: 'He has some bad intentions.' - Predicted sentiment: positive\nSentence: 'They have been to this restaurant before.' - Predicted sentiment: positive\n\nAccuracy without negation handling: 0.6\nAccuracy with negation handling: 0.6\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<span style=\"color:red\"> COMMENT ON YOUR RESULTS</span>","metadata":{"id":"jbQ_xdMU_Hdt"}},{"cell_type":"markdown","source":"Based on the accuracy score of the both techniques, the performance is very similar. I am not quite sure if I did it correctly or not. Or is it because the dataset is too small and the model is overfitting? But based on the result, the performance is identical.  ","metadata":{}},{"cell_type":"markdown","source":"#### C. Train other models and compare performance\nPlot a [reciever operator curve](https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/), and a [calibration plot](https://changhsinlee.com/python-calibration-plot/) for each models listed below trained on a given 80%-20% split of your data.\n\n1. The Nieve Bayes classification model from part A.\n3. Sklearn's implementation of [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)  with `none` as the penalty\n4. Sklearn's implementation of [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) with `elasticnet` as the penalty\n\nPlease plot the results in a way that makes it easy to compare the performance of the three models. If one of your models fails to converge due to [co-linearities](http://www.stat.tamu.edu/~hart/652/collinear.pdf), don't worry - simply report that in your results.","metadata":{"id":"OyqFUssz_Hdt"}},{"cell_type":"code","source":"# ################################################################################\n# # INSERT YOUR CODE HERE\n# # DO NOT FORGET TO PRINT YOUR MEANINGFUL RESULTS TO THE SCREEN.\n# ################################################################################\n# import matplotlib.pyplot as plt\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.calibration import calibration_curve\n# from sklearn.metrics import roc_curve, auc\n\n# print(\"Training Naive Bayes model...\")\n# naive_bayes = MultinomialNB()\n# naive_bayes.fit(X_train, y_train)\n# print(\"Naive Bayes model trained successfully.\")\n\n# print(\"Training Logistic Regression model with none penalty...\")\n# # Train Logistic Regression model with none as the penalty\n# logistic_regression_none = LogisticRegression(penalty=None, solver='lbfgs', max_iter=1000)\n# logistic_regression_none.fit(X_train, y_train)\n# print(\"Logistic Regression (None) model trained successfully.\")\n\n# print(\"Training Logistic Regression model with elastic net penalty...\")\n# logistic_regression_elasticnet = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=1000)\n# logistic_regression_elasticnet.fit(X_train, y_train)\n# print(\"Logistic Regression (Elastic Net) model trained successfully.\")\n\n\n# # Initialize plot\n# plt.figure(figsize=(12, 6))\n\n# # Plot ROC curve for Naive Bayes\n# y_score_nb = naive_bayes.predict_proba(X_test)[:, 1]\n# fpr_nb, tpr_nb, _ = roc_curve(y_test, y_score_nb)\n# roc_auc_nb = auc(fpr_nb, tpr_nb)\n# plt.plot(fpr_nb, tpr_nb, color='blue', lw=2, label='Naive Bayes (AUC = %0.2f)' % roc_auc_nb)\n\n# # Plot ROC curve for Logistic Regression with none penalty\n# y_score_lr_none = logistic_regression_none.predict_proba(X_test)[:, 1]\n# fpr_lr_none, tpr_lr_none, _ = roc_curve(y_test, y_score_lr_none)\n# roc_auc_lr_none = auc(fpr_lr_none, tpr_lr_none)\n# plt.plot(fpr_lr_none, tpr_lr_none, color='red', lw=2, label='Logistic Regression (None) (AUC = %0.2f)' % roc_auc_lr_none)\n\n# # Plot ROC curve for Logistic Regression with elastic net penalty\n# y_score_lr_elasticnet = logistic_regression_elasticnet.predict_proba(X_test)[:, 1]\n# fpr_lr_elasticnet, tpr_lr_elasticnet, _ = roc_curve(y_test, y_score_lr_elasticnet)\n# roc_auc_lr_elasticnet = auc(fpr_lr_elasticnet, tpr_lr_elasticnet)\n# plt.plot(fpr_lr_elasticnet, tpr_lr_elasticnet, color='green', lw=2, label='Logistic Regression (Elastic Net) (AUC = %0.2f)' % roc_auc_lr_elasticnet)\n\n# # Plot ROC curve for random guessing (reference line)\n# plt.plot([0, 1], [0, 1], color='black', lw=1, linestyle='--')\n\n# # Add labels and legend\n# plt.xlim([0.0, 1.0])\n# plt.ylim([0.0, 1.05])\n# plt.xlabel('False Positive Rate')\n# plt.ylabel('True Positive Rate')\n# plt.title('Receiver Operating Characteristic (ROC) Curve')\n# plt.legend(loc='lower right')\n\n# # Show ROC curve plot\n# plt.show()\n\n# # Plot calibration plots for each model\n# plt.figure(figsize=(12, 6))\n\n# # Calibration plot for Naive Bayes\n# prob_pos_nb, mean_pred_value_nb = calibration_curve(y_test, y_score_nb, n_bins=10)\n# plt.plot(mean_pred_value_nb, prob_pos_nb, 's-', color='blue', label='Naive Bayes')\n\n# # Calibration plot for Logistic Regression with none penalty\n# prob_pos_lr_none, mean_pred_value_lr_none = calibration_curve(y_test, y_score_lr_none, n_bins=10)\n# plt.plot(mean_pred_value_lr_none, prob_pos_lr_none, 's-', color='red', label='Logistic Regression (None)')\n\n# # Calibration plot for Logistic Regression with elastic net penalty\n# prob_pos_lr_elasticnet, mean_pred_value_lr_elasticnet = calibration_curve(y_test, y_score_lr_elasticnet, n_bins=10)\n# plt.plot(mean_pred_value_lr_elasticnet, prob_pos_lr_elasticnet, 's-', color='green', label='Logistic Regression (Elastic Net)')\n\n# # Add labels and legend\n# plt.xlabel('Mean Predicted Value')\n# plt.ylabel('Fraction of Positives')\n# plt.title('Calibration Plot')\n# plt.legend(loc='lower right')\n\n# # Show calibration plot\n# plt.show()\n","metadata":{"id":"6RsYh57u_Hdu","execution":{"iopub.status.busy":"2024-03-29T18:01:53.436869Z","iopub.execute_input":"2024-03-29T18:01:53.438130Z","iopub.status.idle":"2024-03-29T18:01:53.448184Z","shell.execute_reply.started":"2024-03-29T18:01:53.438094Z","shell.execute_reply":"2024-03-29T18:01:53.447329Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color:red\"> COMMENT ON ANY NOTABLE DIFFERENCES IN THE PERFORMANCE OF THE METHODS, AND DISCUSS WHY THESE DIFFERENCES MIGHT EXIST</span>","metadata":{"id":"Bfm0lmj-_Hdu"}},{"cell_type":"markdown","source":"#### D. Explore the impact of vocabulary on model performance:\nRepeat the procedure in part C after reducing the number of features in your bag of words. More specifically, regenerate the plots after removing:\n* bottom 1% of ngrams by rank\n* bottom 25% of ngrams by rank\n* top 1% of ngrams by rank\n* top 25% of ngrams by rank\n\nComment on any differences you see in the results based on these changes and speculate on why the removal does (or does not) impact the results.","metadata":{"id":"q_z3gouw_Hdu"}},{"cell_type":"code","source":"# ################################################################################\n# # INSERT YOUR CODE HERE\n# # DO NOT FORGET TO PRINT YOUR MEANINGFUL RESULTS TO THE SCREEN.\n# ################################################################################\n# import numpy as np\n# import matplotlib.pyplot as plt\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.metrics import roc_curve, auc\n# from sklearn.feature_extraction.text import CountVectorizer\n\n# # Function to calculate ngram ranks\n# def calculate_ngram_ranks(X):\n#     ngram_frequencies = np.sum(X, axis=0)\n#     ngram_ranks = np.argsort(ngram_frequencies)\n#     return ngram_ranks\n\n# # Function to remove ngrams based on rank\n# def remove_ngrams_by_rank(X, ngram_ranks, percentile):\n#     cutoff = int(len(ngram_ranks) * percentile)\n#     excluded_ngrams = ngram_ranks[:cutoff]\n#     return np.delete(X, excluded_ngrams, axis=1)\n\n# # Train models with reduced vocabulary\n# def train_models(X_train, y_train, X_test, y_test):\n#     # Train Naive Bayes model\n#     naive_bayes = MultinomialNB()\n#     naive_bayes.fit(X_train, y_train)\n\n#     # Train Logistic Regression model\n#     logistic_regression = LogisticRegression()\n#     logistic_regression.fit(X_train, y_train)\n\n#     return naive_bayes, logistic_regression\n\n# # Generate ROC curve for a model\n# def generate_roc_curve(model, X_test, y_test, label):\n#     y_score = model.predict_proba(X_test)[:, 1]\n#     fpr, tpr, _ = roc_curve(y_test, y_score)\n#     roc_auc = auc(fpr, tpr)\n#     plt.plot(fpr, tpr, lw=2, label='%s (AUC = %0.2f)' % (label, roc_auc))\n\n# # Load and preprocess data\n# # (Assuming X_train, X_test, y_train, y_test are already defined)\n\n# # Calculate ngram ranks\n# ngram_ranks = calculate_ngram_ranks(X_train)\n\n# # Remove bottom 1% of ngrams by rank\n# X_train_bottom1 = remove_ngrams_by_rank(X_train, ngram_ranks, 0.01)\n# X_test_bottom1 = remove_ngrams_by_rank(X_test, ngram_ranks, 0.01)\n\n# # Remove bottom 25% of ngrams by rank\n# X_train_bottom25 = remove_ngrams_by_rank(X_train, ngram_ranks, 0.25)\n# X_test_bottom25 = remove_ngrams_by_rank(X_test, ngram_ranks, 0.25)\n\n# # Remove top 1% of ngrams by rank\n# X_train_top1 = remove_ngrams_by_rank(X_train, ngram_ranks[::-1], 0.01)\n# X_test_top1 = remove_ngrams_by_rank(X_test, ngram_ranks[::-1], 0.01)\n\n# # Remove top 25% of ngrams by rank\n# X_train_top25 = remove_ngrams_by_rank(X_train, ngram_ranks[::-1], 0.25)\n# X_test_top25 = remove_ngrams_by_rank(X_test, ngram_ranks[::-1], 0.25)\n\n# # Train models with reduced vocabulary\n# naive_bayes_bottom1, logistic_regression_bottom1 = train_models(X_train_bottom1, y_train, X_test_bottom1, y_test)\n# naive_bayes_bottom25, logistic_regression_bottom25 = train_models(X_train_bottom25, y_train, X_test_bottom25, y_test)\n# naive_bayes_top1, logistic_regression_top1 = train_models(X_train_top1, y_train, X_test_top1, y_test)\n# naive_bayes_top25, logistic_regression_top25 = train_models(X_train_top25, y_train, X_test_top25, y_test)\n\n# # Generate ROC curves for each model\n# plt.figure(figsize=(10, 6))\n# generate_roc_curve(naive_bayes_bottom1, X_test_bottom1, y_test, 'Naive Bayes (Bottom 1%)')\n# generate_roc_curve(logistic_regression_bottom1, X_test_bottom1, y_test, 'Logistic Regression (Bottom 1%)')\n# generate_roc_curve(naive_bayes_bottom25, X_test_bottom25, y_test, 'Naive Bayes (Bottom 25%)')\n# generate_roc_curve(logistic_regression_bottom25, X_test_bottom25, y_test, 'Logistic Regression (Bottom 25%)')\n# generate_roc_curve(naive_bayes_top1, X_test_top1, y_test, 'Naive Bayes (Top 1%)')\n# generate_roc_curve(logistic_regression_top1, X_test_top1, y_test, 'Logistic Regression (Top 1%)')\n# generate_roc_curve(naive_bayes_top25, X_test_top25, y_test, 'Naive Bayes (Top 25%)')\n# generate_roc_curve(logistic_regression_top25, X_test_top25, y_test, 'Logistic Regression (Top 25%)')\n\n# # Plot ROC curves\n# plt.plot([0, 1], [0, 1], color='black', lw=1, linestyle='--')\n# plt.xlim([0.0, 1.0])\n# plt.ylim([0.0, 1.05])\n# plt.xlabel('False Positive Rate')\n# plt.ylabel('True Positive Rate')\n# plt.title('Receiver Operating Characteristic (ROC) Curve')\n# plt.legend(loc='lower right')\n# plt.show()\n","metadata":{"id":"Mu3CZjDS_Hdu","execution":{"iopub.status.busy":"2024-03-29T18:01:53.449595Z","iopub.execute_input":"2024-03-29T18:01:53.451359Z","iopub.status.idle":"2024-03-29T18:01:53.468461Z","shell.execute_reply.started":"2024-03-29T18:01:53.451324Z","shell.execute_reply":"2024-03-29T18:01:53.467326Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color:red\"> INSERT DISCUSSSION HERE</span>","metadata":{"id":"SmRtKayW_Hdu"}},{"cell_type":"markdown","source":"<hr>\n\n# Part 4: Sentiment Classification\nIn the previous section of this assignment, we demonstrated how to train a model that classifies the author of a text using a bag-of-words. We were able to accomplish this task with relative ease using a supervised learning approach.\n\nThe sentence-author classification problem we tacked in the last section was convenient because we could easily generate the labels for the training data sentences by simply referring back to the author of the book. That is, all sentences in a book are the product of the author, by definition.\n\nBut not all classification problems in NLP are as straight forward as the author classification task we solved in the last section. What if we wanted to classify the sentences in `Russel` and `Nietzsche` according to their sentiment? What would we use for training data? Furthermore, sentiment is not binary; it exists on a spectrum. How would we account for that even if we were to label the sentences?  \n\nOne solution to this problem is to assign a sentiment value to individual words, and to then compute the sentiment of the text based on the properties of those word-level sentiment scores.\n\nFortunately for us, there are resources that provide normalized estimates of word sentiment! One such resource is [SentiWordNet](https://github.com/aesuli/SentiWordNet). SentiWordNet assigns various words in the English language a `positive`, `negative`, and `objective` value score that is normalized between the range of 0 - 1 . You can download the SentiWordNet data from [this address](https://raw.githubusercontent.com/aesuli/SentiWordNet/master/data/SentiWordNet_3.0.0.txt), but I've also included a copy [locally here](https://drive.google.com/file/d/1JgTx-PA_odgIDB9XVGFVFlJCBzvEQcXh/view?usp=sharing). Let's start by importing the data, formatting it and storing it in a dictionary called `sentiment`:","metadata":{"id":"WMJI501B_Hdu"}},{"cell_type":"code","source":"# IMPORT LIBRARY\nimport csv\n\n# INIT DICT TO STORE WORDS AND THEIR SENTIMENT SCORES\nsentiment = {}\n\n# OPEN FILE\nwith open('/kaggle/input/senti-word-net/sentiWord.txt', newline = '') as f:\n\n    # POINT TO CONTENTS\n    csvreader = csv.reader(f, delimiter='\\t')\n\n    # LOOP THROUGH EACH LINE\n    for i, line in enumerate(csvreader):\n\n        # GET HEADERS\n        if i == 0:\n            headers = line\n\n        # OTHERWISE PROCESS DATA\n        else:\n\n            # WORD IS 4th COLUMN\n            words = line[4]\n\n            for word in words.split():\n                # SAVE POS AND NEG SCORE OF WORD\n                sentiment[word] = {'PosScore': line[2], 'NegScore': line[3]}","metadata":{"id":"eRKzhwwg_Hdu","execution":{"iopub.status.busy":"2024-03-29T18:01:53.470112Z","iopub.execute_input":"2024-03-29T18:01:53.470492Z","iopub.status.idle":"2024-03-29T18:01:54.034946Z","shell.execute_reply.started":"2024-03-29T18:01:53.470455Z","shell.execute_reply":"2024-03-29T18:01:54.033786Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"Now that it's imported, let's see what the sentiment value of the word `happy` is:","metadata":{"id":"Kw3NswbB_Hdv"}},{"cell_type":"code","source":"# FIND SCORE OF HAPPY\nprint(sentiment['happy#1']) #1 MEANS ITS FIRST SENSE","metadata":{"id":"wPiJC2AV_Hdv","outputId":"cb491d3e-bac4-4ff6-aeff-26f309a40aa5","execution":{"iopub.status.busy":"2024-03-29T18:01:54.036638Z","iopub.execute_input":"2024-03-29T18:01:54.036971Z","iopub.status.idle":"2024-03-29T18:01:54.044377Z","shell.execute_reply.started":"2024-03-29T18:01:54.036944Z","shell.execute_reply":"2024-03-29T18:01:54.042828Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"{'PosScore': '0.875', 'NegScore': '0'}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"And how about the word `sad`:","metadata":{"id":"c_GAe5PL_Hdv"}},{"cell_type":"code","source":"print(sentiment['sad#1']) #1 MEANS ITS FIRST SENSE","metadata":{"id":"yLsOetc7_Hdv","outputId":"48dab1f1-e781-4790-94ca-41a304d728ba","execution":{"iopub.status.busy":"2024-03-29T18:01:54.045864Z","iopub.execute_input":"2024-03-29T18:01:54.046253Z","iopub.status.idle":"2024-03-29T18:01:54.054543Z","shell.execute_reply.started":"2024-03-29T18:01:54.046221Z","shell.execute_reply":"2024-03-29T18:01:54.053271Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"{'PosScore': '0.125', 'NegScore': '0.75'}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Because words are assigned both a positive an negative score, I can simplify this sentiment value down to a single number by taking the difference between the positive and negative sentiment values:","metadata":{"id":"X8M02bBb_Hdv"}},{"cell_type":"code","source":"print(float(sentiment['sad#1']['PosScore']) - float(sentiment['sad#1']['NegScore']))","metadata":{"id":"FGYS8ebC_Hdv","outputId":"b30e020b-8257-4126-d36f-a91f1003d72b","execution":{"iopub.status.busy":"2024-03-29T18:01:54.055998Z","iopub.execute_input":"2024-03-29T18:01:54.056352Z","iopub.status.idle":"2024-03-29T18:01:54.067130Z","shell.execute_reply.started":"2024-03-29T18:01:54.056320Z","shell.execute_reply":"2024-03-29T18:01:54.065313Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"-0.625\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Learning Exercise 4:\n### Worth 1/5 Points","metadata":{"id":"_xUoIk1D_Hdv"}},{"cell_type":"markdown","source":"#### A. Extract sentiment:\nUse the word-level sentiment scores provided by SentiWordNet to assign a sentiment score to every word, in every sentence of the Russel and Nietzsche texts. For each sentence, sum the sentiment of all words in that sentence and divide by the total number of words in that sentence to create a single normalized sentiment value for each sentence. Generate two histogram that compares the empirical distribution of sentence sentiments for the two authors. Comment on any differences between the distributions. Are the differences statistically significant?\n\nNOTE: For simplicity, please assume the first `sense` of the word in SentiWordNet, as shown in the tutorial example.","metadata":{"id":"oy-oSrIH_Hdv"}},{"cell_type":"code","source":"import csv\n\n# Initialize a dictionary to store words and their sentiment scores\nsentiment = {}\n\n# Open the SentiWordNet file and load data into the sentiment dictionary\nwith open('/kaggle/input/senti-word-net/sentiWord.txt', newline='') as f:\n    csvreader = csv.reader(f, delimiter='\\t')\n    for i, line in enumerate(csvreader):\n        if i > 0:\n            words = line[4].split()\n            for word in words:\n                pos_score = line[2]\n                neg_score = line[3]\n                sentiment[word] = {'PosScore': pos_score, 'NegScore': neg_score}\n\n# print(sentiment)\n# Example texts for Russell and Nietzsche\nRussell_text = Russel\nNietzsche_text = Nietzsche\n\n# Get all the distinct unigrams from the Russel books and the Nietzsche books and combine them\n# vocabulary    = list(set( extract_word_ngrams(Russel, 1) + extract_word_ngrams(Nietzsche, 1) ))\n\n\n# Function to calculate sentiment score for a sentence\ndef calculate_sentence_sentiment(sentence):\n    words = sentence.split()\n    total_sentiment = 0.0  # Initialize total sentiment as a float value\n    word_count = 0\n    for word in words:\n        if word in sentiment:\n            total_sentiment += sentiment[word]['PosScore'] - sentiment[word]['NegScore']\n            word_count += 1\n    if word_count > 0:\n        return total_sentiment / word_count\n    else:\n        return 0.0  # Return float zero if no words with sentiment scores are found\n    \n\n\n# List to store sentiment scores for Russell and Nietzsche sentences\nrussell_sentiments = []\nnietzsche_sentiments = []\n\n# Calculate sentiments for Russell text\nrussell_sentences = Russell_text.split('.')\nfor sentence in russell_sentences:\n    sentiment_score = calculate_sentence_sentiment(sentence)\n    russell_sentiments.append(sentiment_score)\n\n# Calculate sentiments for Nietzsche text\nnietzsche_sentences = Nietzsche_text.split('.')\nfor sentence in nietzsche_sentences:\n    sentiment_score = calculate_sentence_sentiment(sentence)\n    nietzsche_sentiments.append(sentiment_score)","metadata":{"id":"52S7_Sqr_Hdv","execution":{"iopub.status.busy":"2024-03-29T18:01:54.068646Z","iopub.execute_input":"2024-03-29T18:01:54.068976Z","iopub.status.idle":"2024-03-29T18:01:54.676518Z","shell.execute_reply.started":"2024-03-29T18:01:54.068949Z","shell.execute_reply":"2024-03-29T18:01:54.674631Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Set the range and number of bins for the histograms\nbin_range = (-1, 1)  # Range of sentiment scores\nnum_bins = 20  # Number of bins for the histogram\n\nplt.figure(figsize=(10, 6))\n\n# Plot histogram for Russell's sentiments\nplt.hist(russell_sentiments, bins=num_bins, range=bin_range, alpha=0.5, color='blue', label='Russell')\n\n# Plot histogram for Nietzsche's sentiments\nplt.hist(nietzsche_sentiments, bins=num_bins, range=bin_range, alpha=0.5, color='red', label='Nietzsche')\n\nplt.xlabel('Normalized Sentiment Score')\nplt.ylabel('Frequency')\nplt.title('Distribution of Sentence Sentiments')\nplt.legend(loc='upper right')\nplt.grid(True)  # Add grid lines for better visualization\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-29T18:01:54.678124Z","iopub.execute_input":"2024-03-29T18:01:54.678615Z","iopub.status.idle":"2024-03-29T18:01:55.196277Z","shell.execute_reply.started":"2024-03-29T18:01:54.678577Z","shell.execute_reply":"2024-03-29T18:01:55.194915Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x600 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAA1sAAAIjCAYAAAD1OgEdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABtO0lEQVR4nO3deVgVdf//8ddhB+GIC7KEIrnilkullKkpgkumaXealWim2a2ZWVpWt2vlUm6VZotJi1banjuaZhnmkltqpmaaCViZIpqsn98f/jhfTyACMoL4fFwX19XMfM7Me95nOPJqlmMzxhgBAAAAAIqVS0kXAAAAAABlEWELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAzjN27FjZbLbLsq02bdqoTZs2jum1a9fKZrPpo48+uizb79u3r6pXr35ZtlVUqampeuCBBxQUFCSbzaZhw4aVdEkoQTabTWPHji3pMgCgwAhbAMqsuLg42Ww2x4+Xl5dCQkIUExOjl156SadOnSqW7Rw9elRjx47Vtm3bimV9xak011YQzz//vOLi4vTQQw/p3Xff1X333XfBsenp6Zo5c6aaNGkiu90uf39/1a9fXwMHDtRPP/1kaZ0LFizQjBkzLN3G5ZSdna133nlHzZs3V8WKFeXn56fatWurT58+2rBhg6XbXrp06RUdqL777juNHTtWJ06cKOlSAJQCNmOMKekiAMAKcXFx6tevn8aPH6/w8HBlZGQoKSlJa9euVXx8vKpVq6YvvvhCjRo1crwmMzNTmZmZ8vLyKvB2Nm/erBtuuEHz5s1T3759C/y69PR0SZKHh4ekc2e2br31Vi1atEh33nlngddT1NoyMjKUnZ0tT0/PYtmWFVq0aCE3Nzd9++23Fx3bpUsXLVu2THfffbciIyOVkZGhn376SYsXL9aECRMK9d4U1m233aYff/xRv/76q2XbuJyGDBmiWbNmqWvXrmrbtq3c3Ny0d+9eLVu2TL1797Y0DOVsO68/T86ePSs3Nze5ublZtv1L9eKLL2rEiBE6ePBgqT9zDMB6pffTCgCKSceOHXX99dc7pkeNGqWvvvpKt912m26//Xbt2bNH3t7eknRZ/pA7c+aMfHx8HCGrpLi7u5fo9gvi2LFjqlev3kXHbdq0SYsXL9Zzzz2np556ymnZK6+8wlmGQkhOTtbs2bM1YMAAvf76607LZsyYoT/++KOEKlOh/icIAJQGXEYI4KrUtm1b/e9//9OhQ4f03nvvOebndc9WfHy8WrZsKX9/f/n6+qpOnTqOP+jXrl2rG264QZLUr18/xyWLcXFxks7dl9WgQQNt2bJFrVq1ko+Pj+O1/75nK0dWVpaeeuopBQUFqVy5crr99tv122+/OY2pXr16nmdqzl/nxWrL656t06dP67HHHlPVqlXl6empOnXq6MUXX8x1lsFms2nIkCH67LPP1KBBA3l6eqp+/fpavnx53g3/l2PHjql///4KDAyUl5eXrrvuOr399tuO5Tn3rx08eFBLlixx1H6hM0cHDhyQJN188825lrm6uqpSpUpO837//Xfdf//9CgwMdNT+1ltvOY3JqWHhwoV67rnnFBoaKi8vL7Vr10779+93jGvTpo2WLFmiQ4cOOeo8v69paWkaM2aMatasKU9PT1WtWlUjR45UWlpakXv6+++/q3///goJCZGnp6fCw8P10EMPOc6WStKJEyc0bNgwx3tZs2ZNTZ48WdnZ2Xn2MMfBgwdljMmzlzabTVWqVHGaV5Dt/Prrr7LZbHrxxRf1+uuvq0aNGvL09NQNN9ygTZs2Ocb17dtXs2bNcmwr5+f87Z9/Vi3n9/Xnn3/Wvffeq/LlyysgIED/+9//ZIzRb7/9pq5du8putysoKEhTp07NtU/F+f6MHTtWI0aMkCSFh4fnOm7z+ywBUDZxZgvAVeu+++7TU089pZUrV2rAgAF5jtm1a5duu+02NWrUSOPHj5enp6f279+v9evXS5IiIiI0fvx4jR49WgMHDtQtt9wiSbrpppsc6/jrr7/UsWNH9erVS/fee68CAwPzreu5556TzWbTE088oWPHjmnGjBmKiorStm3bHGfgCqIgtZ3PGKPbb79da9asUf/+/dW4cWOtWLFCI0aM0O+//67p06c7jf/222/1ySef6L///a/8/Pz00ksvqUePHjp8+HCucHO+f/75R23atNH+/fs1ZMgQhYeHa9GiRerbt69OnDihRx55RBEREXr33Xf16KOPKjQ0VI899pgkKSAgIM91hoWFSZLmz5+vm2++Od+zk8nJyWrRooXjj+eAgAAtW7ZM/fv3V0pKSq6HcEyaNEkuLi56/PHHdfLkSU2ZMkX33HOPvv/+e0nS008/rZMnT+rIkSOOHvn6+ko6d+/T7bffrm+//VYDBw5URESEdu7cqenTp+vnn3/WZ599VuieHj16VDfeeKNOnDihgQMHqm7duvr999/10Ucf6cyZM/Lw8NCZM2fUunVr/f7773rwwQdVrVo1fffddxo1apQSExPzvb8sp5eLFi3Sf/7zH/n4+FxwbGG3s2DBAp06dUoPPvigbDabpkyZou7du+uXX36Ru7u7HnzwQR09elTx8fF69913L7jdf+vZs6ciIiI0adIkLVmyRM8++6wqVqyo1157TW3bttXkyZM1f/58Pf7447rhhhvUqlUrS96f7t276+eff9b777+v6dOnq3LlypLOHbcX+ywBUEYZACij5s2bZySZTZs2XXBM+fLlTZMmTRzTY8aMMed/NE6fPt1IMn/88ccF17Fp0yYjycybNy/XstatWxtJZs6cOXkua926tWN6zZo1RpK55pprTEpKimP+woULjSQzc+ZMx7ywsDATGxt70XXmV1tsbKwJCwtzTH/22WdGknn22Wedxt15553GZrOZ/fv3O+ZJMh4eHk7ztm/fbiSZl19+Ode2zjdjxgwjybz33nuOeenp6SYyMtL4+vo67XtYWJjp3Llzvuszxpjs7GxHrwMDA83dd99tZs2aZQ4dOpRrbP/+/U1wcLD5888/neb36tXLlC9f3pw5c8YY83/vR0REhElLS3OMmzlzppFkdu7c6ZjXuXNnp17mePfdd42Li4v55ptvnObPmTPHSDLr1693zCtoT/v06WNcXFzyPK6zs7ONMcZMmDDBlCtXzvz8889Oy5988knj6upqDh8+nOu15+vTp4+RZCpUqGDuuOMO8+KLL5o9e/bkGlfQ7Rw8eNBIMpUqVTLHjx93jPv888+NJPPll1865g0ePNhc6M8TSWbMmDGO6Zzf14EDBzrmZWZmmtDQUGOz2cykSZMc8//++2/j7e3t9HtjxfvzwgsvGEnm4MGDTussyGcJgLKHywgBXNV8fX3zfSqhv7+/JOnzzz+/6OVXF+Lp6al+/foVeHyfPn3k5+fnmL7zzjsVHByspUuXFmn7BbV06VK5urpq6NChTvMfe+wxGWO0bNkyp/lRUVGqUaOGY7pRo0ay2+365ZdfLrqdoKAg3X333Y557u7uGjp0qFJTU/X1118XunabzaYVK1bo2WefVYUKFfT+++9r8ODBCgsLU8+ePR33bBlj9PHHH6tLly4yxujPP/90/MTExOjkyZP64YcfnNbdr18/p/vrcs4QXmw/pXNnhyIiIlS3bl2nbbVt21aStGbNGqfxF+tpdna2PvvsM3Xp0sXpPsTz+5Cz3VtuuUUVKlRw2m5UVJSysrK0bt26fOueN2+eXnnlFYWHh+vTTz/V448/roiICLVr106///670/4VZjs9e/ZUhQoVitTL/DzwwAOO/3Z1ddX1118vY4z69+/vmO/v7686deo4bau435/8FMdnCYArD2ELwFUtNTXVKdj8W8+ePXXzzTfrgQceUGBgoHr16qWFCxcW6o+la665plAPw6hVq5bTtM1mU82aNS1/0t2hQ4cUEhKSqx8RERGO5eerVq1arnVUqFBBf//990W3U6tWLbm4OP8TdKHtFJSnp6eefvpp7dmzR0ePHtX777+vFi1aaOHChRoyZIgk6Y8//tCJEyf0+uuvKyAgwOknJxAfO3Ys3/3MCQsX209J2rdvn3bt2pVrW7Vr1y7QtnK2l7OtP/74QykpKWrQoMFFt7t8+fJc242Kispzu//m4uKiwYMHa8uWLfrzzz/1+eefq2PHjvrqq6/Uq1evIm/nUnqZn3+vt3z58vLy8nJcxnf+/PO3VdzvT36K47MEwJWHe7YAXLWOHDmikydPqmbNmhcc4+3trXXr1mnNmjVasmSJli9frg8//FBt27bVypUr5erqetHtFOY+q4K60BcvZ2VlFaim4nCh7ZhS8I0iwcHB6tWrl3r06KH69etr4cKFiouLc/xhe++99yo2NjbP157/VQDSpe1ndna2GjZsqGnTpuW5vGrVqsW2rX9vt3379ho5cmSey3PCREFUqlRJt99+u26//Xa1adNGX3/9tQ4dOqSwsLBCb8eqYyav9RZkW5fz/SmOzxIAVx7CFoCrVs4N+DExMfmOc3FxUbt27dSuXTtNmzZNzz//vJ5++mmtWbNGUVFRFww+RbVv3z6naWOM9u/f7xQCKlSokOfjzA8dOqRrr73WMV2Y2sLCwrRq1SqdOnXK6exWzhcC5zw44VKFhYVpx44dys7Odjq7Vdzbkc5dntioUSPt27dPf/75pwICAuTn56esrCzH2ZficKE+16hRQ9u3b1e7du2K5TgJCAiQ3W7Xjz/+mO+4GjVqKDU1tVj3UZKuv/56ff3110pMTFRYWJgl2ynu36f8FPf7I+Vf/8U+SwCUPVxGCOCq9NVXX2nChAkKDw/XPffcc8Fxx48fzzWvcePGkuR4NHS5cuUkqdi+y+mdd95xuo/so48+UmJiojp27OiYV6NGDW3YsMHpUd+LFy/O9Yj4wtTWqVMnZWVl6ZVXXnGaP336dNlsNqftX4pOnTopKSlJH374oWNeZmamXn75Zfn6+qp169aFXue+fft0+PDhXPNPnDihhIQEVahQQQEBAXJ1dVWPHj308ccf5xlYivodUuXKldPJkydzzb/rrrv0+++/64033si17J9//tHp06cLtR0XFxd169ZNX375pTZv3pxrec4ZlrvuuksJCQlasWJFrjEnTpxQZmbmBbeRlJSk3bt355qfnp6u1atXy8XFxXE2+FK2cyHF/fuUn+J+f6QL11+QzxIAZQ9ntgCUecuWLdNPP/2kzMxMJScn66uvvlJ8fLzCwsL0xRdf5PtFqePHj9e6devUuXNnhYWF6dixY5o9e7ZCQ0PVsmVLSeeCj7+/v+bMmSM/Pz+VK1dOzZs3V3h4eJHqrVixolq2bKl+/fopOTlZM2bMUM2aNZ0eT//AAw/oo48+UocOHXTXXXfpwIEDeu+995xu3i9sbV26dNGtt96qp59+Wr/++quuu+46rVy5Up9//rmGDRuWa91FNXDgQL322mvq27evtmzZourVq+ujjz7S+vXrNWPGjHzvobuQ7du3q3fv3urYsaNuueUWVaxYUb///rvefvttHT16VDNmzHBcpjVp0iStWbNGzZs314ABA1SvXj0dP35cP/zwg1atWpXnH8UX06xZM3344YcaPny4brjhBvn6+qpLly667777tHDhQg0aNEhr1qzRzTffrKysLP30009auHChVqxYkeeDLvLz/PPPa+XKlWrdurXjceWJiYlatGiRvv32W/n7+2vEiBH64osvdNttt6lv375q1qyZTp8+rZ07d+qjjz7Sr7/+mut+phxHjhzRjTfeqLZt26pdu3YKCgrSsWPH9P7772v79u0aNmyY47WXsp38eilJQ4cOVUxMjFxdXZ3uEytOVrw/OfU//fTT6tWrl9zd3dWlS5cCfZYAKINK5iGIAGC9nEe/5/x4eHiYoKAg0759ezNz5kynR4zn+Pej31evXm26du1qQkJCjIeHhwkJCTF33313rkddf/7556ZevXrGzc3N6VHrrVu3NvXr18+zvgs9+v399983o0aNMlWqVDHe3t6mc+fOeT7CfOrUqeaaa64xnp6e5uabbzabN2/Otc78avv3o9+NMebUqVPm0UcfNSEhIcbd3d3UqlXLvPDCC45HiueQZAYPHpyrpgs9kv7fkpOTTb9+/UzlypWNh4eHadiwYZ6Ppy/oo9+Tk5PNpEmTTOvWrU1wcLBxc3MzFSpUMG3btjUfffRRnuMHDx5sqlatatzd3U1QUJBp166def311x1jct6PRYsWOb025zHm59ebmppqevfubfz9/Y0kp76mp6ebyZMnm/r16xtPT09ToUIF06xZMzNu3Dhz8uRJx7jC9PTQoUOmT58+JiAgwHh6epprr73WDB482OkR9adOnTKjRo0yNWvWNB4eHqZy5crmpptuMi+++KJJT0+/YC9TUlLMzJkzTUxMjAkNDTXu7u7Gz8/PREZGmjfeeCPXsVCQ7eT07IUXXsi1Pf3rce6ZmZnm4YcfNgEBAcZmszn9Pv57bM7v678fpx4bG2vKlSuXa1t5/T5a8f5MmDDBXHPNNcbFxcXxGPiCfpYAKFtsxpSCO5kBAAAAoIzhni0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALMCXGhdAdna2jh49Kj8/P9lstpIuBwAAAEAJMcbo1KlTCgkJkYtL/ueuCFsFcPToUVWtWrWkywAAAABQSvz2228KDQ3NdwxhqwD8/PwknWuo3W4v4WqkjIwMrVy5UtHR0XJ3dy/pcsoc+mst+mst+mst+mst+mst+mst+mut0tTflJQUVa1a1ZER8kPYKoCcSwftdnupCVs+Pj6y2+0lfrCVRfTXWvTXWvTXWvTXWvTXWvTXWvTXWqWxvwW5vYgHZAAAAACABQhbAAAAAGABwhYAAAAAWIB7tgAAAIBikpmZqaysrJIuo8zJyMiQm5ubzp49e1n66+7uLldX10teD2ELAAAAuEQZGRmqWLGiDh48yPeyWsAYo6CgIP3222+Xpb82m02hoaHy9fW9pPUQtgAAAIBLkJ2drcOHD6tChQoKCQmRp6cngauYZWdnKzU1Vb6+vhf9IuFLZYzRH3/8oSNHjqhWrVqXdIaLsAUAAABcgvT0dGVnZysgIEB2u93yMHA1ys7OVnp6ury8vC5LfwMCAvTrr78qIyPjksIWRwIAAABQDDibVXYU13tJ2AIAAAAACxC2AAAAAMAC3LMFAAAAWGDs2LK9PautXbtWt956q/7++2/Z7XYtWLBATz31lE6cOFHSpRUYZ7YAAACAq1Tfvn1ls9lks9nk7u6u8PBwjRw5UmfPni3p0soEzmwBAAAAV7EOHTpo3rx5ysjI0JYtWxQbGyubzabJkyeXdGlXvBI9s/Xqq6+qUaNGstvtstvtioyM1LJlyxzL27Rp40jaOT+DBg1yWsfhw4fVuXNn+fj4qEqVKhoxYoQyMzOdxqxdu1ZNmzaVp6enatasqbi4uMuxewAAAECp5+npqaCgIFWtWlXdunVTVFSU4uPjJUnVq1fXjBkznMY3btxYY///NYvGGI0dO1bVqlWTp6enQkJCNHToUMfY2bNnq1atWvLy8lJgYKDuvPNOx7Ls7GxNnDhR4eHh8vb21nXXXaePPvrI8v29nEr0zFZoaKgmTZqkWrVqyRijt99+W127dtXWrVtVv359SdKAAQM0fvx4x2t8fHwc/52VlaXOnTsrKChI3333nRITE9WnTx+5u7vr+eeflyQdPHhQnTt31qBBgzR//nytXr1aDzzwgIKDgxUTE3N5dxgAAAAoxX788Ud99913CgsLK9D4jz/+WNOnT9cHH3yg+vXrKykpSdu3b5ckbd68WUOHDtW7776rm266ScePH9c333zjeO3EiRP13nvvac6cOapVq5bWrVune++9VwEBAWrdurUl+3e5lWjY6tKli9P0c889p1dffVUbNmxwhC0fHx8FBQXl+fqVK1dq9+7dWrVqlQIDA9W4cWNNmDBBTzzxhMaOHSsPDw/NmTNH4eHhmjp1qiQpIiJC3377raZPn37BsJWWlqa0tDTHdEpKiiQpIyNDGRkZl7zflyqnhtJQS1lEf61Ff61Ff61Ff61Ff61Ff62TkZEhY4ykc2d6srOz//9/X97v3crONoV+jTFGixcvlq+vrzIzM5WWliYXFxe99NJL5+3H/+3T+a/Lzs7WoUOHFBQUpLZt28rd3V2hoaG6/vrrlZ2drV9//VXlypVTp06d5Ofnp6pVq+q6665Tdna20tLS9Pzzz2vlypWKjIyUdO4s2jfffKM5c+bolltucWwzOzvb0d+caavlbDOvLzUuzO9QqblnKysrS4sWLdLp06cdDZek+fPn67333lNQUJC6dOmi//3vf46zWwkJCWrYsKECAwMd42NiYvTQQw9p165datKkiRISEhQVFeW0rZiYGA0bNuyCtUycOFHjxo3LNX/lypVOZ9ZKWs7pXViD/lqL/lqL/lqL/lqL/lqL/hY/Nzc3x8mBU6dOOeanpXld1jpSUgr/UIuMjAzdcsstmjp1qk6fPq1XX31Vbm5uat++vVJSUpSdna2zZ886Tj5I5/5uT0tLU0pKimJiYjR9+nRde+21ioqKUvv27dWhQwe5ubmpefPmCg0NVY0aNdSuXTu1a9dOt912m3x8fLRnzx6dOXMm18mP9PR0NWrUSCkpKTpz5oykcz11cTl395MxxqkWq6Snp+uff/7RunXrct2ilFNXQZR42Nq5c6ciIyN19uxZ+fr66tNPP1W9evUkSb1791ZYWJhCQkK0Y8cOPfHEE9q7d68++eQTSVJSUpJT0JLkmE5KSsp3TEpKiv755x95e3vnqmnUqFEaPny4YzolJUVVq1ZVdHS07HZ78e18EWVkZCg+Pl7t27eXu7t7SZdT5tBfa9Ffa9Ffa9Ffa9Ffa9Ff65w9e1aHDx+WJPn5+clmO3dGy9Pz8p7Zsts9Cv0ad3d32e12NW7cWJIUGRmpJk2aaNGiRerfv7/c3Nzk6enp9Ddwdna2Y169evW0d+9erVq1SqtWrdKIESM0e/ZsrVmzRna7XVu3btXatWsVHx+vyZMn64UXXtD333/vWNeXX36pa665xqmmnHXnnOTw8/OTn5+fJMlms12Wv8fPnj0rb29vtWrVSl5ezqG5MGGvxMNWnTp1tG3bNp08eVIfffSRYmNj9fXXX6tevXoaOHCgY1zDhg0VHBysdu3a6cCBA6pRo4ZlNXl6esrT0zPXfHd391L14VTa6ilr6K+16K+16K+16K+16K+16G/xy8rKcgQsm83mOAtju7xZSy4uhd9gzkPocmp2cXHRU089peHDhzvun0pKSnIsT0lJ0cGDB51eU65cOXXt2lVdu3bVkCFDVLduXe3atUtNmzaVh4eHoqOjFR0drbFjx8rf319r165V+/bt5enpqSNHjujWW2+9wP78X02285qZM99KOdvM6/elML8/JR62PDw8VLNmTUlSs2bNtGnTJs2cOVOvvfZarrHNmzeXJO3fv181atRQUFCQNm7c6DQmOTlZkhyncoOCghzzzh9jt9vzPKsFAMDFTJwoXYZbBi6qrH2BKYDS4T//+Y9GjBihWbNmqW3btoqLi1OXLl3k7++v0aNHO93DFBcXp6ysLDVv3lw+Pj5677335O3trbCwMC1evFi//PKLWrVqpQoVKmjp0qXKzs5WnTp15Ofnp8cff1yPPvqosrOz1bJlS508eVLr16+X3W5XbGxsCXag+JR42Pq3nBvm8rJt2zZJUnBwsKRzpzmfe+45HTt2TFWqVJF07jrknFOaOWOWLl3qtJ74+Hin+8IAAACA4nal/g8RNzc3DRkyRFOmTNG+fft08OBB3XbbbSpfvrwmTJiggwcPOsb6+/tr0qRJGj58uLKystSwYUN9+eWXqlSpkvz9/fXJJ59o7NixOnv2rGrVqqX333/f8SC8CRMmKCAgQBMnTtQvv/wif39/NW3aVE899VRJ7XqxK9GwNWrUKHXs2FHVqlXTqVOntGDBAq1du1YrVqzQgQMHtGDBAnXq1EmVKlXSjh079Oijj6pVq1Zq1KiRJCk6Olr16tXTfffdpylTpigpKUnPPPOMBg8e7LgMcNCgQXrllVc0cuRI3X///frqq6+0cOFCLVmypCR3HQAAAChxF/r+2SeffFJPPvmkJOmDDz5wWnb+Wadu3bqpW7duea6jZcuWWrt27QW3bbPZ9Mgjj+iRRx7Jc3mbNm0cTyHMzs5W7969c33nbmlXomHr2LFj6tOnjxITE1W+fHk1atRIK1asUPv27fXbb79p1apVmjFjhk6fPq2qVauqR48eeuaZZxyvd3V11eLFi/XQQw8pMjJS5cqVU2xsrNP3coWHh2vJkiV69NFHNXPmTIWGhurNN9/kO7YAAAAAWKpEw9bcuXMvuKxq1ar6+uuvL7qOsLCwXJcJ/lubNm20devWQtcHAAAAAEVl/aM8AAAAAOAqRNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAIl+j1bAAAAQJk1dmyZ2F5cXJyGDRumEydOWLL+S1Wa6+PMFgAAAHCV6tu3r2w2myZNmuQ0/7PPPpPNZpMk9ezZUz///HOh1muz2fTZZ58VV5lXLMIWAAAAcBXz8vLS5MmT9ffff+e53NvbW1WqVLnMVZUNhC0AAADgKhYVFaWgoCBNnDgxz+VxcXHy9/d3mvf555+radOm8vLy0rXXXqtx48YpMzNTklS9enVJ0h133CGbzeaYrl69umw2W64fSUpPT9eQIUMUHBwsLy8vhYWFOdVz4sQJDRs2zLG8QYMGWrx4sVNNK1asUEREhHx9fdWhQwclJiY6LX/zzTcVEREhLy8v1a1bV7Nnzy5qywqMe7YAAACAq5irq6uef/559e7dW0OHDlVoaGi+47/55hv16dNHL730km655RYdOHBAAwcOlCSNGTNGmzZtUpUqVTRv3jx16NBBrq6ukqRNmzYpKytLkpSVlaU777xT7u7ukqSXXnpJX3zxhRYuXKhq1arpt99+02+//SZJys7OVufOnXXixAm98847qlWrlnbv3u1YrySdOXNGL774ot599125uLjo3nvv1eOPP6758+dLkubPn6/Ro0frlVdeUZMmTbR161YNGDBA5cqVU2xsbPE29DyELQAAAOAqd8cdd6hx48YaM2aM5s6dm+/YcePG6cknn3SElGuvvVYTJkzQyJEjNWbMGAUEBEiS/P39FRQU5HhdznxJeuSRR5SYmKhNmzZJkg4fPqxatWqpZcuWstlsCgsLc4xdtWqVNm7cqO+//15NmzaVi4uLrr32WqeaMjIyNGfOHNWoUUOSNGTIEI0fP96xfMyYMZo6daq6d+8uSQoPD9fu3bv12muvEbYAAAAAWGvy5Mlq27atHn/88XzHbd++XevXr9dzzz3nmJeVlaWzZ8/qzJkz8vHxyff1r7/+uubOnavvvvvOEcD69u2r9u3bq06dOurQoYNuu+02RUdHS5K2bdum0NBQ1axZ84Lr9PHxcQQtSQoODtaxY8ckSadPn9aBAwfUv39/DRgwwDEmMzNT5cuXz7fWS0XYAgAAAKBWrVopJiZGo0aNUt++fS84LjU1VePGjXOcJTqfl5dXvttYs2aNHn74Yb3//vtq1KiRY37Tpk118OBBLVu2TKtWrdJdd92lqKgoffTRR/L29r5o7TmXI+aw2WwyxjjqlaQ33nhDzZs3dxp3/qWIViBsAQAAAJAkTZo0SY0bN1adOnUuOKZp06bau3dvvmea3N3dHfdn5di/f7/uvPNOPfXUU3kGNbvdrp49e6pnz56688471aFDBx0/flyNGjXSkSNHtH//fjVt2rTQ+xQYGKiQkBD98ssvuueeewr9+ktB2AIAAAAgSWrYsKHuuecevfTSSxccM3r0aN12222qVq2a7rzzTrm4uGj79u368ccf9eyzz0o69+TB1atX6+abb5anp6e8vLzUpUsXNWnSRAMHDlRSUpJjfUFBQZo2bZqCg4PVpEkTubi4aNGiRQoKCpK/v79at26tVq1aqU+fPpo+fbpq166tn376STabTR06dCjQfo0bN05Dhw5V+fLl1aFDB6WlpWnz5s36+++/NXz48EtrWj4IWwAAAIAVxo4t6QqKZPz48frwww8vuDwmJkaLFy/W+PHjNXnyZLm7u6tu3bp64IEHHGOmTp2q4cOH64033tA111yjtWvX6qefftJPP/2kkJAQp/UZY+Tn56cpU6Zo3759cnV11Q033KClS5fKxeXcN1UtWrRIw4YN0z333KPTp0+rZs2aub6IOT8PPPCAfHx89MILL2jEiBEqV66cGjZsqGHDhhWuOYVE2AIAAACuUnFxcbnmVa9eXWlpaY7pvn375rqHKyYmRjExMRdcb5cuXdSlSxeneTn3UOVlwIABTg+v+LeKFSvqlVdekd1udwSw/Orr1q1bru317t1bvXv3vuA2rMCXGgMAAACABQhbAAAAAGABwhYAAAAAWICwBQAAAAAWIGwBAAAAxSC/B0DgylJc7yVhCwAAALgE7u7ukqT09PQSrgTFJee9dHV1vaT18Oh3AAAK6ZZvJ8qWnl3SZUgaW9IFANC5P8jtdrv++OMPeXl5ydfXVzabraTLKlOys7OVnp6us2fP5nr0uxXb+uOPP+Tj4yM3t0uLS4QtAAAA4BJVqVJFP//8szw9PfXnn3+WdDlljjFG//zzj7y9vS9LkHVxcVG1atUueVuELQAAAOAS2Ww2nTp1SjfddFNJl1ImZWRkaN26dWrVqpXjsk0reXh4FMsZNMIWAAAAUExcXV0vSxi42ri6uiozM1NeXl5XVH95QAYAAAAAWICwBQAAAAAWIGwBAAAAgAUIWwAAAABgAcIWAAAAAFiAsAUAAAAAFiBsAQAAAIAFCFsAAAAAYAHCFgAAAABYgLAFAAAAABYgbAEAAACABQhbAAAAAGABwhYAAAAAWICwBQAAAAAWIGwBAAAAgAUIWwAAAABgAcIWAAAAAFiAsAUAAAAAFiBsAQAAAIAFCFsAAAAAYAHCFgAAAABYgLAFAAAAABYgbAEAAACABUo0bL366qtq1KiR7Ha77Ha7IiMjtWzZMsfys2fPavDgwapUqZJ8fX3Vo0cPJScnO63j8OHD6ty5s3x8fFSlShWNGDFCmZmZTmPWrl2rpk2bytPTUzVr1lRcXNzl2D0AAAAAV7ESDVuhoaGaNGmStmzZos2bN6tt27bq2rWrdu3aJUl69NFH9eWXX2rRokX6+uuvdfToUXXv3t3x+qysLHXu3Fnp6en67rvv9PbbbysuLk6jR492jDl48KA6d+6sW2+9Vdu2bdOwYcP0wAMPaMWKFZd9fwEAAABcPdxKcuNdunRxmn7uuef06quvasOGDQoNDdXcuXO1YMECtW3bVpI0b948RUREaMOGDWrRooVWrlyp3bt3a9WqVQoMDFTjxo01YcIEPfHEExo7dqw8PDw0Z84chYeHa+rUqZKkiIgIffvtt5o+fbpiYmIu+z4DAAAAuDqUaNg6X1ZWlhYtWqTTp08rMjJSW7ZsUUZGhqKiohxj6tatq2rVqikhIUEtWrRQQkKCGjZsqMDAQMeYmJgYPfTQQ9q1a5eaNGmihIQEp3XkjBk2bNgFa0lLS1NaWppjOiUlRZKUkZGhjIyMYtrjosupoTTUUhbRX2vRX2vRX2vl9NW4l45bnsva+8zxay36ay36a63S1N/C1FDiYWvnzp2KjIzU2bNn5evrq08//VT16tXTtm3b5OHhIX9/f6fxgYGBSkpKkiQlJSU5Ba2c5TnL8huTkpKif/75R97e3rlqmjhxosaNG5dr/sqVK+Xj41PkfS1u8fHxJV1CmUZ/rUV/rUV/rXVqYMOSLkGStHTp0pIuwRIcv9aiv9aiv9YqDf09c+ZMgceWeNiqU6eOtm3bppMnT+qjjz5SbGysvv766xKtadSoURo+fLhjOiUlRVWrVlV0dLTsdnsJVnZORkaG4uPj1b59e7m7u5d0OWUO/bUW/bUW/bVWTn/9Xt8pW0Z2SZejlktGlXQJxYrj11r011r011qlqb85V70VRImHLQ8PD9WsWVOS1KxZM23atEkzZ85Uz549lZ6erhMnTjid3UpOTlZQUJAkKSgoSBs3bnRaX87TCs8f8+8nGCYnJ8tut+d5VkuSPD095enpmWu+u7t7ib+55ytt9ZQ19Nda9Nda9Ndatoxs2dJLPmyV1feY49da9Nda9NdapaG/hdl+6bjo/DzZ2dlKS0tTs2bN5O7urtWrVzuW7d27V4cPH1ZkZKQkKTIyUjt37tSxY8ccY+Lj42W321WvXj3HmPPXkTMmZx0AAAAAYIUSPbM1atQodezYUdWqVdOpU6e0YMECrV27VitWrFD58uXVv39/DR8+XBUrVpTdbtfDDz+syMhItWjRQpIUHR2tevXq6b777tOUKVOUlJSkZ555RoMHD3acmRo0aJBeeeUVjRw5Uvfff7+++uorLVy4UEuWLCnJXQcAAABQxpVo2Dp27Jj69OmjxMRElS9fXo0aNdKKFSvUvn17SdL06dPl4uKiHj16KC0tTTExMZo9e7bj9a6urlq8eLEeeughRUZGqly5coqNjdX48eMdY8LDw7VkyRI9+uijmjlzpkJDQ/Xmm2/y2HcAAAAAlirRsDV37tx8l3t5eWnWrFmaNWvWBceEhYVd9GlMbdq00datW4tUIwAAAAAURam7ZwsAAAAAygLCFgAAAABYgLAFAAAAABYgbAEAAACABQhbAAAAAGABwhYAAAAAWICwBQAAAAAWIGwBAAAAgAUIWwAAAABgAcIWAAAAAFiAsAUAAAAAFiBsAQAAAIAFCFsAAAAAYAHCFgAAAABYgLAFAAAAABYgbAEAAACABQhbAAAAAGABwhYAAAAAWICwBQAAAAAWIGwBAAAAgAUIWwAAAABgAcIWAAAAAFiAsAUAAAAAFiBsAQAAAIAFCFsAAAAAYAHCFgAAAABYgLAFAAAAABYgbAEAAACABQhbAAAAAGABwhYAAAAAWICwBQAAAAAWIGwBAAAAgAUIWwAAAABgAcIWAAAAAFiAsAUAAAAAFiBsAQAAAIAFCFsAAAAAYAHCFgAAAABYgLAFAAAAABYgbAEAAACABQhbAAAAAGABwhYAAAAAWICwBQAAAAAWIGwBAAAAgAUIWwAAAABgAcIWAAAAAFiAsAUAAAAAFiBsAQAAAIAFCFsAAAAAYAHCFgAAAABYgLAFAAAAABYgbAEAAACABUo0bE2cOFE33HCD/Pz8VKVKFXXr1k179+51GtOmTRvZbDann0GDBjmNOXz4sDp37iwfHx9VqVJFI0aMUGZmptOYtWvXqmnTpvL09FTNmjUVFxdn9e4BAAAAuIqVaNj6+uuvNXjwYG3YsEHx8fHKyMhQdHS0Tp8+7TRuwIABSkxMdPxMmTLFsSwrK0udO3dWenq6vvvuO7399tuKi4vT6NGjHWMOHjyozp0769Zbb9W2bds0bNgwPfDAA1qxYsVl21cAAAAAVxe3ktz48uXLnabj4uJUpUoVbdmyRa1atXLM9/HxUVBQUJ7rWLlypXbv3q1Vq1YpMDBQjRs31oQJE/TEE09o7Nix8vDw0Jw5cxQeHq6pU6dKkiIiIvTtt99q+vTpiomJsW4HAQAAAFy1SjRs/dvJkyclSRUrVnSaP3/+fL333nsKCgpSly5d9L///U8+Pj6SpISEBDVs2FCBgYGO8TExMXrooYe0a9cuNWnSRAkJCYqKinJaZ0xMjIYNG5ZnHWlpaUpLS3NMp6SkSJIyMjKUkZFxyft5qXJqKA21lEX011r011r011o5fTXupeOW57L2PnP8Wov+Wov+Wqs09bcwNZSasJWdna1hw4bp5ptvVoMGDRzze/furbCwMIWEhGjHjh164okntHfvXn3yySeSpKSkJKegJckxnZSUlO+YlJQU/fPPP/L29nZaNnHiRI0bNy5XjStXrnSEvNIgPj6+pEso0+ivteivteivtU4NbFjSJUiSli5dWtIlWILj11r011r011qlob9nzpwp8NhSE7YGDx6sH3/8Ud9++63T/IEDBzr+u2HDhgoODla7du104MAB1ahRw5JaRo0apeHDhzumU1JSVLVqVUVHR8tut1uyzcLIyMhQfHy82rdvL3d395Iup8yhv9aiv9aiv9bK6a/f6ztly8gu6XLUcsmoki6hWHH8Wov+Wov+Wqs09TfnqreCKBVha8iQIVq8eLHWrVun0NDQfMc2b95ckrR//37VqFFDQUFB2rhxo9OY5ORkSXLc5xUUFOSYd/4Yu92e66yWJHl6esrT0zPXfHd39xJ/c89X2uopa+ivteivteivtWwZ2bKll3zYKqvvMcevteivteivtUpDfwuz/RK96NwYoyFDhujTTz/VV199pfDw8Iu+Ztu2bZKk4OBgSVJkZKR27typY8eOOcbEx8fLbrerXr16jjGrV692Wk98fLwiIyOLaU8AAAAAwFmJhq3Bgwfrvffe04IFC+Tn56ekpCQlJSXpn3/+kSQdOHBAEyZM0JYtW/Trr7/qiy++UJ8+fdSqVSs1atRIkhQdHa169erpvvvu0/bt27VixQo988wzGjx4sOPs1KBBg/TLL79o5MiR+umnnzR79mwtXLhQjz76aIntOwAAAICyrUTD1quvvqqTJ0+qTZs2Cg4Odvx8+OGHkiQPDw+tWrVK0dHRqlu3rh577DH16NFDX375pWMdrq6uWrx4sVxdXRUZGal7771Xffr00fjx4x1jwsPDtWTJEsXHx+u6667T1KlT9eabb/LYdwAAAACWKdF7towx+S6vWrWqvv7664uuJyws7KJPZGrTpo22bt1aqPoAAAAAoKhKxxeFAAAAAEAZQ9gCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxQpLD1yy+/FHcdAAAAAFCmFCls1axZU7feeqvee+89nT17trhrAgAAAIArXpHC1g8//KBGjRpp+PDhCgoK0oMPPqiNGzcWd20AAAAAcMUqUthq3LixZs6cqaNHj+qtt95SYmKiWrZsqQYNGmjatGn6448/irtOAAAAALiiXNIDMtzc3NS9e3ctWrRIkydP1v79+/X444+ratWq6tOnjxITE4urTgAAAAC4olxS2Nq8ebP++9//Kjg4WNOmTdPjjz+uAwcOKD4+XkePHlXXrl2Lq04AAAAAuKK4FeVF06ZN07x587R371516tRJ77zzjjp16iQXl3PZLTw8XHFxcapevXpx1goAAAAAV4windl69dVX1bt3bx06dEifffaZbrvtNkfQylGlShXNnTs33/VMnDhRN9xwg/z8/FSlShV169ZNe/fudRpz9uxZDR48WJUqVZKvr6969Oih5ORkpzGHDx9W586d5ePjoypVqmjEiBHKzMx0GrN27Vo1bdpUnp6eqlmzpuLi4oqy6wAAAABQIEUKW/v27dOoUaMUHBx8wTEeHh6KjY3Ndz1ff/21Bg8erA0bNig+Pl4ZGRmKjo7W6dOnHWMeffRRffnll1q0aJG+/vprHT16VN27d3csz8rKUufOnZWenq7vvvtOb7/9tuLi4jR69GjHmIMHD6pz58669dZbtW3bNg0bNkwPPPCAVqxYUZTdBwAAAICLKtJlhPPmzZOvr6/+85//OM1ftGiRzpw5c9GQlWP58uVO03FxcapSpYq2bNmiVq1a6eTJk5o7d64WLFigtm3bOrYdERGhDRs2qEWLFlq5cqV2796tVatWKTAwUI0bN9aECRP0xBNPaOzYsfLw8NCcOXMUHh6uqVOnSpIiIiL07bffavr06YqJiSlKCwAAAAAgX0UKWxMnTtRrr72Wa36VKlU0cODAAoetfzt58qQkqWLFipKkLVu2KCMjQ1FRUY4xdevWVbVq1ZSQkKAWLVooISFBDRs2VGBgoGNMTEyMHnroIe3atUtNmjRRQkKC0zpyxgwbNizPOtLS0pSWluaYTklJkSRlZGQoIyOjSPtWnHJqKA21lEX011r011r011o5fTXul/R8qWJT1t5njl9r0V9r0V9rlab+FqaGIoWtw4cPKzw8PNf8sLAwHT58uCirVHZ2toYNG6abb75ZDRo0kCQlJSXJw8ND/v7+TmMDAwOVlJTkGHN+0MpZnrMsvzEpKSn6559/5O3t7bRs4sSJGjduXK4aV65cKR8fnyLtnxXi4+NLuoQyjf5ai/5ai/5a69TAhiVdgiRp6dKlJV2CJTh+rUV/rUV/rVUa+nvmzJkCjy1S2KpSpYp27NiR62mD27dvV6VKlYqySg0ePFg//vijvv322yK9vjiNGjVKw4cPd0ynpKSoatWqio6Olt1uL8HKzsnIyFB8fLzat28vd3f3ki6nzKG/1qK/1qK/1srpr9/rO2XLyC7pctRyyaiSLqFYcfxai/5ai/5aqzT1N+eqt4IoUti6++67NXToUPn5+alVq1aSzj3s4pFHHlGvXr0Kvb4hQ4Zo8eLFWrdunUJDQx3zg4KClJ6erhMnTjid3UpOTlZQUJBjzMaNG53Wl/O0wvPH/PsJhsnJybLb7bnOakmSp6enPD09c813d3cv8Tf3fKWtnrKG/lqL/lqL/lrLlpEtW3rJh62y+h5z/FqL/lqL/lqrNPS3MNsv0kXnEyZMUPPmzdWuXTt5e3vL29tb0dHRatu2rZ5//vkCr8cYoyFDhujTTz/VV199levSxGbNmsnd3V2rV692zNu7d68OHz6syMhISVJkZKR27typY8eOOcbEx8fLbrerXr16jjHnryNnTM46AAAAAKC4FenMloeHhz788ENNmDBB27dvl7e3txo2bKiwsLBCrWfw4MFasGCBPv/8c/n5+TnusSpfvry8vb1Vvnx59e/fX8OHD1fFihVlt9v18MMPKzIyUi1atJAkRUdHq169errvvvs0ZcoUJSUl6ZlnntHgwYMdZ6cGDRqkV155RSNHjtT999+vr776SgsXLtSSJUuKsvsAAAAAcFFFCls5ateurdq1axf59a+++qokqU2bNk7z582bp759+0qSpk+fLhcXF/Xo0UNpaWmKiYnR7NmzHWNdXV21ePFiPfTQQ4qMjFS5cuUUGxur8ePHO8aEh4dryZIlevTRRzVz5kyFhobqzTff5LHvAAAAACxTpLCVlZWluLg4rV69WseOHVN2tvN161999VWB1mOMuegYLy8vzZo1S7NmzbrgmLCwsIs+kalNmzbaunVrgeoCAAAAgEtVpLD1yCOPKC4uTp07d1aDBg1ks9mKuy4AAAAAuKIVKWx98MEHWrhwoTp16lTc9QAAAABAmVCkpxF6eHioZs2axV0LAAAAAJQZRQpbjz32mGbOnFmge64AAAAA4GpUpMsIv/32W61Zs0bLli1T/fr1c32x1yeffFIsxQEAAADAlapIYcvf31933HFHcdcCAAAAAGVGkcLWvHnzirsOAAAAAChTinTPliRlZmZq1apVeu2113Tq1ClJ0tGjR5WamlpsxQEAAADAlapIZ7YOHTqkDh066PDhw0pLS1P79u3l5+enyZMnKy0tTXPmzCnuOgEAAADgilKkM1uPPPKIrr/+ev3999/y9vZ2zL/jjju0evXqYisOAAAAAK5URTqz9c033+i7776Th4eH0/zq1avr999/L5bCAAAAAOBKVqQzW9nZ2crKyso1/8iRI/Lz87vkogAAAADgSleksBUdHa0ZM2Y4pm02m1JTUzVmzBh16tSpuGoDAAAAgCtWkS4jnDp1qmJiYlSvXj2dPXtWvXv31r59+1S5cmW9//77xV0jAAAAAFxxihS2QkNDtX37dn3wwQfasWOHUlNT1b9/f91zzz1OD8wAAAAAgKtVkcKWJLm5uenee+8tzloAAAAAoMwoUth655138l3ep0+fIhUDAAAAAGVFkcLWI4884jSdkZGhM2fOyMPDQz4+PoQtAAAAAFe9Ij2N8O+//3b6SU1N1d69e9WyZUsekAEAAAAAKmLYykutWrU0adKkXGe9AAAAAOBqVGxhSzr30IyjR48W5yoBAAAA4IpUpHu2vvjiC6dpY4wSExP1yiuv6Oabby6WwgAAAADgSlaksNWtWzenaZvNpoCAALVt21ZTp04tjroAAAAA4IpWpLCVnZ1d3HUAAAAAQJlSrPdsAQAAAADOKdKZreHDhxd47LRp04qyCQAAAAC4ohUpbG3dulVbt25VRkaG6tSpI0n6+eef5erqqqZNmzrG2Wy24qkSAAAAAK4wRQpbXbp0kZ+fn95++21VqFBB0rkvOu7Xr59uueUWPfbYY8VaJAAAAABcaYp0z9bUqVM1ceJER9CSpAoVKujZZ5/laYQAAAAAoCKGrZSUFP3xxx+55v/xxx86derUJRcFAAAAAFe6IoWtO+64Q/369dMnn3yiI0eO6MiRI/r444/Vv39/de/evbhrBAAAAIArTpHu2ZozZ44ef/xx9e7dWxkZGedW5Oam/v3764UXXijWAgEAAADgSlSksOXj46PZs2frhRde0IEDByRJNWrUULly5Yq1OAAAAAC4Ul3SlxonJiYqMTFRtWrVUrly5WSMKa66AAAAAOCKVqSw9ddff6ldu3aqXbu2OnXqpMTERElS//79eew7AAAAAKiIYevRRx+Vu7u7Dh8+LB8fH8f8nj17avny5cVWHAAAAABcqYp0z9bKlSu1YsUKhYaGOs2vVauWDh06VCyFAQAAAMCVrEhntk6fPu10RivH8ePH5enpeclFAQAAAMCVrkhh65ZbbtE777zjmLbZbMrOztaUKVN06623FltxAAAAAHClKtJlhFOmTFG7du20efNmpaena+TIkdq1a5eOHz+u9evXF3eNAAAAAHDFKdKZrQYNGujnn39Wy5Yt1bVrV50+fVrdu3fX1q1bVaNGjeKuEQAAAACuOIU+s5WRkaEOHTpozpw5evrpp62oCQAAAACueIU+s+Xu7q4dO3ZYUQsAAAAAlBlFuozw3nvv1dy5c4u7FgAAAAAoM4r0gIzMzEy99dZbWrVqlZo1a6Zy5co5LZ82bVqxFAcAAAAAV6pCha1ffvlF1atX148//qimTZtKkn7++WenMTabrfiqAwAAAIArVKHCVq1atZSYmKg1a9ZIknr27KmXXnpJgYGBlhQHAAAAAFeqQt2zZYxxml62bJlOnz5drAUBAAAAQFlQpAdk5Ph3+AIAAAAAnFOosGWz2XLdk8U9WgAAAACQW6Hu2TLGqG/fvvL09JQknT17VoMGDcr1NMJPPvmk+CoEAAAAgCtQocJWbGys0/S9995brMUAAAAAQFlRqLA1b968Yt34unXr9MILL2jLli1KTEzUp59+qm7dujmW9+3bV2+//bbTa2JiYrR8+XLH9PHjx/Xwww/ryy+/lIuLi3r06KGZM2fK19fXMWbHjh0aPHiwNm3apICAAD388MMaOXJkse4LAAAAAJzvkh6QcalOnz6t6667TrNmzbrgmA4dOigxMdHx8/777zstv+eee7Rr1y7Fx8dr8eLFWrdunQYOHOhYnpKSoujoaIWFhWnLli164YUXNHbsWL3++uuW7RcAAAAAFOrMVnHr2LGjOnbsmO8YT09PBQUF5blsz549Wr58uTZt2qTrr79ekvTyyy+rU6dOevHFFxUSEqL58+crPT1db731ljw8PFS/fn1t27ZN06ZNcwplAAAAAFCcSjRsFcTatWtVpUoVVahQQW3bttWzzz6rSpUqSZISEhLk7+/vCFqSFBUVJRcXF33//fe64447lJCQoFatWsnDw8MxJiYmRpMnT9bff/+tChUq5NpmWlqa0tLSHNMpKSmSpIyMDGVkZFi1qwWWU0NpqKUsor/Wor/Wor/WyumrcS/RC0Mcytr7zPFrLfprLfprrdLU38LUUKrDVocOHdS9e3eFh4frwIEDeuqpp9SxY0clJCTI1dVVSUlJqlKlitNr3NzcVLFiRSUlJUmSkpKSFB4e7jQmMDDQsSyvsDVx4kSNGzcu1/yVK1fKx8enuHbvksXHx5d0CWUa/bUW/bUW/bXWqYENS7oESdLSpUtLugRLcPxai/5ai/5aqzT098yZMwUeW6rDVq9evRz/3bBhQzVq1Eg1atTQ2rVr1a5dO8u2O2rUKA0fPtwxnZKSoqpVqyo6Olp2u92y7RZURkaG4uPj1b59e7m7u5d0OWUO/bUW/bUW/bVWTn/9Xt8pW0Z2SZejlktGlXQJxYrj11r011r011qlqb85V70VRKkOW/927bXXqnLlytq/f7/atWunoKAgHTt2zGlMZmamjh8/7rjPKygoSMnJyU5jcqYvdC+Yp6en47vEzufu7l7ib+75Sls9ZQ39tRb9tRb9tZYtI1u29JIPW2X1Peb4tRb9tRb9tVZp6G9htl86LjovoCNHjuivv/5ScHCwJCkyMlInTpzQli1bHGO++uorZWdnq3nz5o4x69atc7q2Mj4+XnXq1MnzEkIAAAAAKA4lGrZSU1O1bds2bdu2TZJ08OBBbdu2TYcPH1ZqaqpGjBihDRs26Ndff9Xq1avVtWtX1axZUzExMZKkiIgIdejQQQMGDNDGjRu1fv16DRkyRL169VJISIgkqXfv3vLw8FD//v21a9cuffjhh5o5c6bTZYIAAAAAUNxKNGxt3rxZTZo0UZMmTSRJw4cPV5MmTTR69Gi5urpqx44duv3221W7dm31799fzZo10zfffON0id/8+fNVt25dtWvXTp06dVLLli2dvkOrfPnyWrlypQ4ePKhmzZrpscce0+jRo3nsOwAAAABLleg9W23atJEx5oLLV6xYcdF1VKxYUQsWLMh3TKNGjfTNN98Uuj4AAAAAKKor6p4tAAAAALhSELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxQomFr3bp16tKli0JCQmSz2fTZZ585LTfGaPTo0QoODpa3t7eioqK0b98+pzHHjx/XPffcI7vdLn9/f/Xv31+pqalOY3bs2KFbbrlFXl5eqlq1qqZMmWL1rgEAAAC4ypVo2Dp9+rSuu+46zZo1K8/lU6ZM0UsvvaQ5c+bo+++/V7ly5RQTE6OzZ886xtxzzz3atWuX4uPjtXjxYq1bt04DBw50LE9JSVF0dLTCwsK0ZcsWvfDCCxo7dqxef/11y/cPAAAAwNXLrSQ33rFjR3Xs2DHPZcYYzZgxQ88884y6du0qSXrnnXcUGBiozz77TL169dKePXu0fPlybdq0Sddff70k6eWXX1anTp304osvKiQkRPPnz1d6erreeusteXh4qH79+tq2bZumTZvmFMoAAAAAoDiVaNjKz8GDB5WUlKSoqCjHvPLly6t58+ZKSEhQr169lJCQIH9/f0fQkqSoqCi5uLjo+++/1x133KGEhAS1atVKHh4ejjExMTGaPHmy/v77b1WoUCHXttPS0pSWluaYTklJkSRlZGQoIyPDit0tlJwaSkMtZRH9tRb9tRb9tVZOX4176bjluay9zxy/1qK/1qK/1ipN/S1MDaU2bCUlJUmSAgMDneYHBgY6liUlJalKlSpOy93c3FSxYkWnMeHh4bnWkbMsr7A1ceJEjRs3Ltf8lStXysfHp4h7VPzi4+NLuoQyjf5ai/5ai/5a69TAhiVdgiRp6dKlJV2CJTh+rUV/rUV/rVUa+nvmzJkCjy21YaskjRo1SsOHD3dMp6SkqGrVqoqOjpbdbi/Bys7JyMhQfHy82rdvL3d395Iup8yhv9aiv9aiv9bK6a/f6ztly8gu6XLUcsmoki6hWHH8Wov+Wov+Wqs09TfnqreCKLVhKygoSJKUnJys4OBgx/zk5GQ1btzYMebYsWNOr8vMzNTx48cdrw8KClJycrLTmJzpnDH/5unpKU9Pz1zz3d3dS/zNPV9pq6esob/Wor/Wor/WsmVky5Ze8mGrrL7HHL/Wor/Wor/WKg39Lcz2S8dF53kIDw9XUFCQVq9e7ZiXkpKi77//XpGRkZKkyMhInThxQlu2bHGM+eqrr5Sdna3mzZs7xqxbt87p2sr4+HjVqVMnz0sIAQAAAKA4lGjYSk1N1bZt27Rt2zZJ5x6KsW3bNh0+fFg2m03Dhg3Ts88+qy+++EI7d+5Unz59FBISom7dukmSIiIi1KFDBw0YMEAbN27U+vXrNWTIEPXq1UshISGSpN69e8vDw0P9+/fXrl279OGHH2rmzJlOlwkCAAAAQHEr0csIN2/erFtvvdUxnROAYmNjFRcXp5EjR+r06dMaOHCgTpw4oZYtW2r58uXy8vJyvGb+/PkaMmSI2rVrJxcXF/Xo0UMvvfSSY3n58uW1cuVKDR48WM2aNVPlypU1evRoHvsOAAAAwFIlGrbatGkjY8wFl9tsNo0fP17jx4+/4JiKFStqwYIF+W6nUaNG+uabb4pcJwAAAAAUVqm9ZwsAAAAArmSELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMACpTpsjR07Vjabzemnbt26juVnz57V4MGDValSJfn6+qpHjx5KTk52Wsfhw4fVuXNn+fj4qEqVKhoxYoQyMzMv964AAAAAuMq4lXQBF1O/fn2tWrXKMe3m9n8lP/roo1qyZIkWLVqk8uXLa8iQIerevbvWr18vScrKylLnzp0VFBSk7777TomJierTp4/c3d31/PPPX/Z9AQAAAHD1KPVhy83NTUFBQbnmnzx5UnPnztWCBQvUtm1bSdK8efMUERGhDRs2qEWLFlq5cqV2796tVatWKTAwUI0bN9aECRP0xBNPaOzYsfLw8LjcuwMAAADgKlHqw9a+ffsUEhIiLy8vRUZGauLEiapWrZq2bNmijIwMRUVFOcbWrVtX1apVU0JCglq0aKGEhAQ1bNhQgYGBjjExMTF66KGHtGvXLjVp0iTPbaalpSktLc0xnZKSIknKyMhQRkaGRXtacDk1lIZayiL6ay36ay36a62cvhr30nEVfll7nzl+rUV/rUV/rVWa+luYGmzGGGNhLZdk2bJlSk1NVZ06dZSYmKhx48bp999/148//qgvv/xS/fr1cwpFknTjjTfq1ltv1eTJkzVw4EAdOnRIK1ascCw/c+aMypUrp6VLl6pjx455bnfs2LEaN25crvkLFiyQj49P8e4kAAAAgCvGmTNn1Lt3b508eVJ2uz3fsaX6zNb5YahRo0Zq3ry5wsLCtHDhQnl7e1u23VGjRmn48OGO6ZSUFFWtWlXR0dEXbejlkJGRofj4eLVv317u7u4lXU6ZQ3+tRX+tRX+tldNfv9d3ypaRXdLlqOWSUSVdQrHi+LUW/bUW/bVWaepvzlVvBVGqw9a/+fv7q3bt2tq/f7/at2+v9PR0nThxQv7+/o4xycnJjnu8goKCtHHjRqd15DytMK/7wHJ4enrK09Mz13x3d/cSf3PPV9rqKWvor7Xor7Xor7VsGdmypZd82Cqr7zHHr7Xor7Xor7VKQ38Ls/3ScdF5AaWmpurAgQMKDg5Ws2bN5O7urtWrVzuW7927V4cPH1ZkZKQkKTIyUjt37tSxY8ccY+Lj42W321WvXr3LXj8AAACAq0epPrP1+OOPq0uXLgoLC9PRo0c1ZswYubq66u6771b58uXVv39/DR8+XBUrVpTdbtfDDz+syMhItWjRQpIUHR2tevXq6b777tOUKVOUlJSkZ555RoMHD87zzBUAAAAAFJdSHbaOHDmiu+++W3/99ZcCAgLUsmVLbdiwQQEBAZKk6dOny8XFRT169FBaWppiYmI0e/Zsx+tdXV21ePFiPfTQQ4qMjFS5cuUUGxur8ePHl9QuAQAAALhKlOqw9cEHH+S73MvLS7NmzdKsWbMuOCYsLExLly4t7tIAAAAAIF9X1D1bAAAAAHClIGwBAAAAgAUIWwAAAABgAcIWAAAAAFiAsAUAAAAAFiBsAQAAAIAFCFsAAAAAYAHCFgAAAABYgLAFAAAAABYgbAEAAACABQhbAAAAAGABwhYAAAAAWICwBQAAAAAWIGwBAAAAgAUIWwAAAABgAcIWAAAAAFiAsAUAAAAAFiBsAQAAAIAFCFsAAAAAYAHCFgAAAABYgLAFAAAAABYgbAEAAACABQhbAAAAAGABwhYAAAAAWICwBQAAAAAWIGwBAAAAgAUIWwAAAABgAcIWAAAAAFiAsAUAAAAAFiBsAQAAAIAFCFsAAAAAYAHCFgAAAABYgLAFAAAAABYgbAEAAACABQhbAAAAAGABwhYAAAAAWICwBQAAAAAWIGwBAAAAgAUIWwAAAABgAcIWAAAAAFiAsAUAAAAAFiBsAQAAAIAFCFsAAAAAYAHCFgAAAABYgLAFAAAAABYgbAEAAACABQhbAAAAAGABwhYAAAAAWICwBQAAAAAWIGwBAAAAgAUIWwAAAABgAcIWAAAAAFjgqgpbs2bNUvXq1eXl5aXmzZtr48aNJV0SAAAAgDLqqglbH374oYYPH64xY8bohx9+0HXXXaeYmBgdO3aspEsDAAAAUAZdNWFr2rRpGjBggPr166d69eppzpw58vHx0VtvvVXSpQEAAAAog9xKuoDLIT09XVu2bNGoUaMc81xcXBQVFaWEhIRc49PS0pSWluaYPnnypCTp+PHjysjIsL7gi8jIyNCZM2f0119/yd3dvaTLKXPor7Xor7Xor7Vy+uuidNlcsku6HP31118lXUKx4vi1Fv21Fv21Vmnq76lTpyRJxpiLjr0qwtaff/6prKwsBQYGOs0PDAzUTz/9lGv8xIkTNW7cuFzzw8PDLasRAIBCqzyxpCsAgKvWqVOnVL58+XzHXBVhq7BGjRql4cOHO6azs7N1/PhxVapUSTabrQQrOyclJUVVq1bVb7/9JrvdXtLllDn011r011r011r011r011r011r011qlqb/GGJ06dUohISEXHXtVhK3KlSvL1dVVycnJTvOTk5MVFBSUa7ynp6c8PT2d5vn7+1tZYpHY7fYSP9jKMvprLfprLfprLfprLfprLfprLfprrdLS34ud0cpxVTwgw8PDQ82aNdPq1asd87Kzs7V69WpFRkaWYGUAAAAAyqqr4syWJA0fPlyxsbG6/vrrdeONN2rGjBk6ffq0+vXrV9KlAQAAACiDrpqw1bNnT/3xxx8aPXq0kpKS1LhxYy1fvjzXQzOuBJ6enhozZkyuSx1RPOivteivteivteivteivteivteivta7U/tpMQZ5ZCAAAAAAolKvini0AAAAAuNwIWwAAAABgAcIWAAAAAFiAsAUAAAAAFiBslULPPfecbrrpJvn4+BT4y5SNMRo9erSCg4Pl7e2tqKgo7du3z2nM8ePHdc8998hut8vf31/9+/dXamqqBXtQuhW2D7/++qtsNlueP4sWLXKMy2v5Bx98cDl2qVQpynHWpk2bXL0bNGiQ05jDhw+rc+fO8vHxUZUqVTRixAhlZmZauSulUmH7e/z4cT388MOqU6eOvL29Va1aNQ0dOlQnT550Gne1Hr+zZs1S9erV5eXlpebNm2vjxo35jl+0aJHq1q0rLy8vNWzYUEuXLnVaXpDP4qtNYXr8xhtv6JZbblGFChVUoUIFRUVF5Rrft2/fXMdqhw4drN6NUqsw/Y2Li8vVOy8vL6cxHMPOCtPfvP4ts9ls6ty5s2MMx+8569atU5cuXRQSEiKbzabPPvvsoq9Zu3atmjZtKk9PT9WsWVNxcXG5xhT2M/2yMCh1Ro8ebaZNm2aGDx9uypcvX6DXTJo0yZQvX9589tlnZvv27eb222834eHh5p9//nGM6dChg7nuuuvMhg0bzDfffGNq1qxp7r77bov2ovQqbB8yMzNNYmKi08+4ceOMr6+vOXXqlGOcJDNv3jyncef3/2pRlOOsdevWZsCAAU69O3nypGN5ZmamadCggYmKijJbt241S5cuNZUrVzajRo2yendKncL2d+fOnaZ79+7miy++MPv37zerV682tWrVMj169HAadzUevx988IHx8PAwb731ltm1a5cZMGCA8ff3N8nJyXmOX79+vXF1dTVTpkwxu3fvNs8884xxd3c3O3fudIwpyGfx1aSwPe7du7eZNWuW2bp1q9mzZ4/p27evKV++vDly5IhjTGxsrOnQoYPTsXr8+PHLtUulSmH7O2/ePGO32516l5SU5DSGY/j/FLa/f/31l1Nvf/zxR+Pq6mrmzZvnGMPxe87SpUvN008/bT755BMjyXz66af5jv/ll1+Mj4+PGT58uNm9e7d5+eWXjaurq1m+fLljTGHfr8uFsFWKzZs3r0BhKzs72wQFBZkXXnjBMe/EiRPG09PTvP/++8YYY3bv3m0kmU2bNjnGLFu2zNhsNvP7778Xe+2lVXH1oXHjxub+++93mleQD4uyrqj9bd26tXnkkUcuuHzp0qXGxcXF6Y+CV1991djtdpOWllYstV8Jiuv4XbhwofHw8DAZGRmOeVfj8XvjjTeawYMHO6azsrJMSEiImThxYp7j77rrLtO5c2enec2bNzcPPvigMaZgn8VXm8L2+N8yMzONn5+fefvttx3zYmNjTdeuXYu71CtSYft7sb8rOIadXerxO336dOPn52dSU1Md8zh+cyvIvz8jR4409evXd5rXs2dPExMT45i+1PfLKlxGWAYcPHhQSUlJioqKcswrX768mjdvroSEBElSQkKC/P39df311zvGREVFycXFRd9///1lr7mkFEcftmzZom3btql///65lg0ePFiVK1fWjTfeqLfeekvmKvsau0vp7/z581W5cmU1aNBAo0aN0pkzZ5zW27BhQ6cvIY+JiVFKSop27dpV/DtSShXX7/HJkydlt9vl5ub8vfZX0/Gbnp6uLVu2OH1uuri4KCoqyvG5+W8JCQlO46Vzx2HO+IJ8Fl9NitLjfztz5owyMjJUsWJFp/lr165VlSpVVKdOHT300EP666+/irX2K0FR+5uamqqwsDBVrVpVXbt2dfoM5Rj+P8Vx/M6dO1e9evVSuXLlnOZz/BbexT5/i+P9sorbxYegtEtKSpIkpz9Ec6ZzliUlJalKlSpOy93c3FSxYkXHmKtBcfRh7ty5ioiI0E033eQ0f/z48Wrbtq18fHy0cuVK/fe//1VqaqqGDh1abPWXdkXtb+/evRUWFqaQkBDt2LFDTzzxhPbu3atPPvnEsd68ju+cZVeL4jh+//zzT02YMEEDBw50mn+1Hb9//vmnsrKy8jyufvrppzxfc6Hj8PzP2Zx5FxpzNSlKj//tiSeeUEhIiNMfUB06dFD37t0VHh6uAwcO6KmnnlLHjh2VkJAgV1fXYt2H0qwo/a1Tp47eeustNWrUSCdPntSLL76om266Sbt27VJoaCjH8Hku9fjduHGjfvzxR82dO9dpPsdv0Vzo8zclJUX//POP/v7770v+vLEKYesyefLJJzV58uR8x+zZs0d169a9TBWVLQXt76X6559/tGDBAv3vf//Ltez8eU2aNNHp06f1wgsvlIk/Vq3u7/l/+Dds2FDBwcFq166dDhw4oBo1ahR5vVeKy3X8pqSkqHPnzqpXr57Gjh3rtKwsH7+4Mk2aNEkffPCB1q5d6/QQh169ejn+u2HDhmrUqJFq1KihtWvXql27diVR6hUjMjJSkZGRjumbbrpJEREReu211zRhwoQSrKzsmTt3rho2bKgbb7zRaT7H79WHsHWZPPbYY+rbt2++Y6699toirTsoKEiSlJycrODgYMf85ORkNW7c2DHm2LFjTq/LzMzU8ePHHa+/khW0v5fah48++khnzpxRnz59Ljq2efPmmjBhgtLS0uTp6XnR8aXZ5epvjubNm0uS9u/frxo1aigoKCjXE4WSk5MlieO3gP09deqUOnToID8/P3366adyd3fPd3xZOn7zUrlyZbm6ujqOoxzJyckX7GVQUFC+4wvyWXw1KUqPc7z44ouaNGmSVq1apUaNGuU79tprr1XlypW1f//+q+qP1Uvpbw53d3c1adJE+/fvl8QxfL5L6e/p06f1wQcfaPz48RfdztV6/BbWhT5/7Xa7vL295erqesm/D1bhnq3LJCAgQHXr1s33x8PDo0jrDg8PV1BQkFavXu2Yl5KSou+//97xf7AiIyN14sQJbdmyxTHmq6++UnZ2tuMP2ytZQft7qX2YO3eubr/9dgUEBFx07LZt21ShQoUy8Yfq5epvjm3btkmS4x/7yMhI7dy50yloxMfHy263q169esWzkyXI6v6mpKQoOjpaHh4e+uKLL3I96jkvZen4zYuHh4eaNWvm9LmZnZ2t1atXO/2f//NFRkY6jZfOHYc54wvyWXw1KUqPJWnKlCmaMGGCli9f7nR/4oUcOXJEf/31l1M4uBoUtb/ny8rK0s6dOx294xj+P5fS30WLFiktLU333nvvRbdztR6/hXWxz9/i+H2wTIk+ngN5OnTokNm6davj8eJbt241W7dudXrMeJ06dcwnn3zimJ40aZLx9/c3n3/+udmxY4fp2rVrno9+b9Kkifn+++/Nt99+a2rVqnXVPvo9vz4cOXLE1KlTx3z//fdOr9u3b5+x2Wxm2bJludb5xRdfmDfeeMPs3LnT7Nu3z8yePdv4+PiY0aNHW74/pU1h+7t//34zfvx4s3nzZnPw4EHz+eefm2uvvda0atXK8ZqcR79HR0ebbdu2meXLl5uAgICr9tHvhenvyZMnTfPmzU3Dhg3N/v37nR43nJmZaYy5eo/fDz74wHh6epq4uDize/duM3DgQOPv7+946uV9991nnnzyScf49evXGzc3N/Piiy+aPXv2mDFjxuT56PeLfRZfTQrb40mTJhkPDw/z0UcfOR2rOf/+nTp1yjz++OMmISHBHDx40Kxatco0bdrU1KpVy5w9e7ZE9rEkFba/48aNMytWrDAHDhwwW7ZsMb169TJeXl5m165djjEcw/+nsP3N0bJlS9OzZ89c8zl+/8+pU6ccf99KMtOmTTNbt241hw4dMsYY8+STT5r77rvPMT7n0e8jRowwe/bsMbNmzcrz0e/5vV8lhbBVCsXGxhpJuX7WrFnjGKP//504ObKzs83//vc/ExgYaDw9PU27du3M3r17ndb7119/mbvvvtv4+voau91u+vXr5xTgrhYX68PBgwdz9dsYY0aNGmWqVq1qsrKycq1z2bJlpnHjxsbX19eUK1fOXHfddWbOnDl5ji3rCtvfw4cPm1atWpmKFSsaT09PU7NmTTNixAin79kyxphff/3VdOzY0Xh7e5vKlSubxx57zOnR5VeLwvZ3zZo1eX6eSDIHDx40xlzdx+/LL79sqlWrZjw8PMyNN95oNmzY4FjWunVrExsb6zR+4cKFpnbt2sbDw8PUr1/fLFmyxGl5QT6LrzaF6XFYWFiex+qYMWOMMcacOXPGREdHm4CAAOPu7m7CwsLMgAEDSvyPqZJUmP4OGzbMMTYwMNB06tTJ/PDDD07r4xh2VtjPiJ9++slIMitXrsy1Lo7f/3Ohf5ty+hkbG2tat26d6zWNGzc2Hh4e5tprr3X6OzhHfu9XSbEZU4af7QsAAAAAJYR7tgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AACWWrt2rWw2m06cOCFJiouLk7+/v6Xb7Nu3r7p162bpNi5F9erVNWPGjJIuAwBgMcIWAFwh+vbtK5vNpkmTJjnN/+yzz2Sz2UqoqsLr2bOnfv7555IuQ2+88Yauu+46+fr6yt/fX02aNNHEiROLdRsXCpabNm3SwIEDi3VbRfHvIJyfy9EvAChr3Eq6AABAwXl5eWny5Ml68MEHVaFChWJbb3p6ujw8PIptffnx9vaWt7f3ZdnWhbz11lsaNmyYXnrpJbVu3VppaWnasWOHfvzxx8uy/YCAgMuyneJSEv26nMckAFiFM1sAcAWJiopSUFDQRc8ofPzxx6pfv748PT1VvXp1TZ061Wl59erVNWHCBPXp00d2u10DBw50nIVZvHix6tSpIx8fH9155506c+aM3n77bVWvXl0VKlTQ0KFDlZWV5VjXu+++q+uvv15+fn4KCgpS7969dezYsQvW9u+zPdWrV5fNZsv1k+O3337TXXfdJX9/f1WsWFFdu3bVr7/+6lielZWl4cOHy9/fX5UqVdLIkSNljMm3P1988YXuuusu9e/fXzVr1lT9+vV1991367nnnnMa9+abbyoiIkJeXl6qW7euZs+e7Vj266+/ymaz6ZNPPtGtt94qHx8fXXfddUpISJB07qxRv379dPLkScc+jR071rHP519GaLPZ9Nprr+m2226Tj4+PIiIilJCQoP3796tNmzYqV66cbrrpJh04cMCpvs8//1xNmzaVl5eXrr32Wo0bN06ZmZlO633zzTd1xx13yMfHR7Vq1dIXX3zhqP/WW2+VJFWoUEE2m019+/a9pH699dZbjuMuODhYQ4YMcSw7fPiwunbtKl9fX9ntdt11111KTk52LB87dqwaN26sN998U+Hh4fLy8pIknThxQg888IACAgJkt9vVtm1bbd++/YLvLQCUKgYAcEWIjY01Xbt2NZ988onx8vIyv/32mzHGmE8//dSc/3G+efNm4+LiYsaPH2/27t1r5s2bZ7y9vc28efMcY8LCwozdbjcvvvii2b9/v9m/f7+ZN2+ecXd3N+3btzc//PCD+frrr02lSpVMdHS0ueuuu8yuXbvMl19+aTw8PMwHH3zgWNfcuXPN0qVLzYEDB0xCQoKJjIw0HTt2dCxfs2aNkWT+/vtvY4wx8+bNM+XLl3csP3bsmElMTDSJiYnmyJEjpkWLFuaWW24xxhiTnp5uIiIizP3332927Nhhdu/ebXr37m3q1Klj0tLSjDHGTJ482VSoUMF8/PHHZvfu3aZ///7Gz8/PdO3a9YK9fPDBB03dunXNr7/+esEx7733ngkODjYff/yx+eWXX8zHH39sKlasaOLi4owxxhw8eNBIMnXr1jWLFy82e/fuNXfeeacJCwszGRkZJi0tzcyYMcPY7XbH/p06dcrR/+nTpzu2Jclcc8015sMPPzR79+413bp1M9WrVzdt27Y1y5cvN7t37zYtWrQwHTp0cLxm3bp1xm63m7i4OHPgwAGzcuVKU716dTN27Fin9YaGhpoFCxaYffv2maFDhxpfX1/z119/mczMTPPxxx8bSWbv3r0mMTHRnDhxosj9mj17tvHy8jIzZswwe/fuNRs3bnTsY1ZWlmncuLFp2bKl2bx5s9mwYYNp1qyZad26teP1Y8aMMeXKlTMdOnQwP/zwg9m+fbsxxpioqCjTpUsXs2nTJvPzzz+bxx57zFSqVMn89ddfF6wFAEoLwhYAXCFywpYxxrRo0cLcf//9xpjcYat3796mffv2Tq8dMWKEqVevnmM6LCzMdOvWzWnMvHnzjCSzf/9+x7wHH3zQ+Pj4OEKCMcbExMSYBx988IJ1btq0yUhyvOZiYet8Q4cONWFhYebYsWPGGGPeffddU6dOHZOdne0Yk5aWZry9vc2KFSuMMcYEBwebKVOmOJZnZGSY0NDQfMPW0aNHTYsWLYwkU7t2bRMbG2s+/PBDk5WV5RhTo0YNs2DBAqfXTZgwwURGRhpj/i9svfnmm47lu3btMpLMnj178t3XvMLWM88845hOSEgwkszcuXMd895//33j5eXlmG7Xrp15/vnnndb77rvvmuDg4AuuNzU11Ugyy5YtM8bkfm8upCD9CgkJMU8//XSer1+5cqVxdXU1hw8fdszL6dXGjRuNMefClru7u+O9N8aYb775xtjtdnP27Fmn9dWoUcO89tpr+dYMAKUBlxECwBVo8uTJevvtt7Vnz55cy/bs2aObb77Zad7NN9+sffv2OV3+d/311+d6rY+Pj2rUqOGYDgwMVPXq1eXr6+s07/zLBLds2aIuXbqoWrVq8vPzU+vWrSWdu2ysMF5//XXNnTtXX3zxheOepu3bt2v//v3y8/OTr6+vfH19VbFiRZ09e1YHDhzQyZMnlZiYqObNmzvW4+bmlue+nS84OFgJCQnauXOnHnnkEWVmZio2NlYdOnRQdna2Tp8+rQMHDqh///6O7fr6+urZZ5/NdSlfo0aNnNYrKd/LKC/k/PUEBgZKkho2bOg07+zZs0pJSXH0Zvz48U71DRgwQImJiTpz5kye6y1Xrpzsdnuh67tYv44dO6ajR4+qXbt2eb5+z549qlq1qqpWreqYV69ePfn7+zsdw2FhYU73s23fvl2pqamqVKmS034ePHgw1/sAAKURD8gAgCtQq1atFBMTo1GjRl3wPpuLKVeuXK557u7uTtM2my3PednZ2ZKk06dPKyYmRjExMZo/f74CAgJ0+PBhxcTEKD09vcC1rFmzRg8//LDef/99p3CQmpqqZs2aaf78+bleUxwPmWjQoIEaNGig//73vxo0aJBuueUWff3116pXr56kc0/gOz/ISZKrq6vT9Pn9ybnXLKc/hZHXevJbd2pqqsaNG6fu3bvnWlfO/U7/XkfOeopSn3Thfl0s3BbUv4/J1NRUBQcHa+3atbnGWv31AQBQHAhbAHCFmjRpkho3bqw6deo4zY+IiND69eud5q1fv161a9fOFRQu1U8//aS//vpLkyZNcpy12Lx5c6HWsX//ft1555166qmncgWHpk2b6sMPP1SVKlVkt9vzfH1wcLC+//57tWrVSpKUmZmpLVu2qGnTpoWqIydgnT59WoGBgQoJCdEvv/yie+65p1DrOZ+Hh4fT2cTi1LRpU+3du1c1a9Ys8jpynvZXlBrP75efn5+qV6+u1atXOx66cb6IiAj99ttv+u233xzHye7du3XixAnHevLStGlTJSUlyc3NTdWrVy90jQBQ0ghbAHCFatiwoe655x699NJLTvMfe+wx3XDDDZowYYJ69uyphIQEvfLKK05P0isu1apVk4eHh15++WUNGjRIP/74oyZMmFDg1//zzz/q0qWLmjRpooEDByopKcmxLCgoSPfcc49eeOEFde3aVePHj1doaKgOHTqkTz75RCNHjlRoaKgeeeQRTZo0SbVq1VLdunU1bdq0i35v1EMPPaSQkBC1bdtWoaGhSkxM1LPPPquAgABFRkZKksaNG6ehQ4eqfPny6tChg9LS0rR582b9/fffGj58eIH2r3r16kpNTdXq1at13XXXycfHRz4+PgXuT35Gjx6t2267TdWqVdOdd94pFxcXbd++XT/++KOeffbZAq0jLCxMNptNixcvVqdOneTt7e10yWiOgvRr7NixGjRokKpUqaKOHTvq1KlTWr9+vR5++GFFRUU5jtcZM2YoMzNT//3vf9W6det8z4pFRUUpMjJS3bp105QpU1S7dm0dPXpUS5Ys0R133FFsZ9QAwCrcswUAV7Dx48fnuiSsadOmWrhwoT744AM1aNBAo0eP1vjx44t8uWF+AgICFBcXp0WLFqlevXqaNGmSXnzxxQK/Pjk5WT/99JNWr16tkJAQBQcHO36kc/eQrVu3TtWqVVP37t0VERGh/v376+zZs44zXY899pjuu+8+xcbGKjIyUn5+frrjjjvy3W5UVJQ2bNig//znP6pdu7Z69OghLy8vrV69WpUqVZIkPfDAA3rzzTc1b948NWzYUK1bt1ZcXJzCw8MLvH833XSTBg0apJ49eyogIEBTpkwp8GsvJiYmRosXL9bKlSt1ww03qEWLFpo+fbrCwsIKvI5rrrlG48aN05NPPqnAwECnR7WfryD9io2N1YwZMzR79mzVr19ft912m/bt2yfp3KWLn3/+uSpUqKBWrVopKipK1157rT788MN867PZbFq6dKlatWqlfv36qXbt2urVq5cOHTrkuK8NAEozmzEX+TISAAAAAEChcWYLAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAL/D+sYVM7CSMpjAAAAAElFTkSuQmCC"},"metadata":{}}]},{"cell_type":"markdown","source":"<span style=\"color:red\"> INSERT AN INTERPRETATION OF YOUR RESULTS HERE </span>","metadata":{"id":"n2b35SsP_Hdw"}},{"cell_type":"markdown","source":"#### B. Use of sentiment as a feature:\nTrain a logistic regression model which takes as input\n* a bag-of-words representation of the sentences (uni-grams) and\n* the sentence sentiment you just computed\n\nto predict the identity of the author, just as we did in Learning Exercise 3. If your model does not converge, use a coherent strategy to remove bag-of-words features until it does.","metadata":{"id":"qvgqulDa_Hdw"}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n# Assuming you have already computed russell_sentences, russell_sentiments, nietzsche_sentences, and nietzsche_sentiments\n\n# Step 1: Combine Russell's and Nietzsche's sentences and sentiments\nall_sentences = russell_sentences + nietzsche_sentences\nall_sentiments = russell_sentiments + nietzsche_sentiments\n\n# Step 2: Define a common vocabulary using the union of unigrams from both authors\nvocabulary = list(set(extract_word_ngrams(Russel, 1) + extract_word_ngrams(Nietzsche, 1)))\n\n# Step 3: Extract bag-of-words representations for each sentence using the common vocabulary\nvectorizer = CountVectorizer(vocabulary=vocabulary)\nX_bow = vectorizer.fit_transform(all_sentences)\n\n# Step 4: Combine bag-of-words representations and sentence sentiments as features\nX_sentiments = np.array(all_sentiments).reshape(-1, 1)\nX_combined = np.hstack((X_bow.toarray(), X_sentiments))\n\n# Step 5: Split the data into training and testing sets\ny_labels = [1] * len(russell_sentences) + [0] * len(nietzsche_sentences)\nX_train, X_test, y_train, y_test = train_test_split(X_combined, y_labels, test_size=0.2, random_state=42)\n\n# Step 6: Train a logistic regression model\nlogistic_regression = LogisticRegression(max_iter=1000)  # Adjust max_iter if needed for convergence\nlogistic_regression.fit(X_train, y_train)\n\n# Step 7: Evaluate the trained model\ny_pred_train = logistic_regression.predict(X_train)\ny_pred_test = logistic_regression.predict(X_test)\n\naccuracy_train = accuracy_score(y_train, y_pred_train)\naccuracy_test = accuracy_score(y_test, y_pred_test)\n\nprint(\"Train Accuracy:\", accuracy_train)\nprint(\"Test Accuracy:\", accuracy_test)\n","metadata":{"id":"QtYvHrwh_Hdw","execution":{"iopub.status.busy":"2024-03-29T18:01:55.197862Z","iopub.execute_input":"2024-03-29T18:01:55.198338Z","iopub.status.idle":"2024-03-29T18:02:14.247939Z","shell.execute_reply.started":"2024-03-29T18:01:55.198296Z","shell.execute_reply":"2024-03-29T18:02:14.246403Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Train Accuracy: 0.9176120513297378\nTest Accuracy: 0.79182156133829\n","output_type":"stream"}]},{"cell_type":"code","source":"import random\n\n# Combine all sentences and their corresponding labels\nall_sentences = russell_sentences + nietzsche_sentences\nall_labels = [1] * len(russell_sentences) + [0] * len(nietzsche_sentences)\n\n# Randomly select some sentences\nsample_size = 5\nrandom_indices = random.sample(range(len(all_sentences)), sample_size)\nrandom_sentences = [all_sentences[idx] for idx in random_indices]\nactual_authors = [all_labels[idx] for idx in random_indices]\n\n# Compute sentiment scores for the sample sentences\nsample_sentiments = [calculate_sentence_sentiment(sentence) for sentence in random_sentences]\n\n# Extract bag-of-words representations for the sample sentences using the common vocabulary\nsample_bow = vectorizer.transform(random_sentences)\n\n# Combine bag-of-words representations and sentence sentiments as features for the sample sentences\nsample_combined = np.hstack((sample_bow.toarray(), np.array(sample_sentiments).reshape(-1, 1)))\n\n# Predict the author for the sample sentences\nauthor_predictions = logistic_regression.predict(sample_combined)\n\n# Print the predictions along with the actual authors\nfor sentence, actual_author, prediction in zip(random_sentences, actual_authors, author_predictions):\n    predicted_author = \"Russell\" if prediction == 1 else \"Nietzsche\"\n    actual_author_name = \"Russell\" if actual_author == 1 else \"Nietzsche\"\n    print(f\"Sentence: '{sentence}' - Actual Author: {actual_author_name}, Predicted Author: {predicted_author}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-29T18:02:14.257792Z","iopub.execute_input":"2024-03-29T18:02:14.259145Z","iopub.status.idle":"2024-03-29T18:02:14.283429Z","shell.execute_reply.started":"2024-03-29T18:02:14.259074Z","shell.execute_reply":"2024-03-29T18:02:14.281641Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Sentence: 'org' - Actual Author: Russell, Predicted Author: Nietzsche\nSentence: '\nthe german soul has passages and galleries in it, there are caves,\nhiding-places, and dungeons therein, its disorder has much of the charm\nof the mysterious, the german is well acquainted with the bypaths to\nchaos' - Actual Author: Nietzsche, Predicted Author: Nietzsche\nSentence: ' not to cleave to any person, be it even the\ndearest--every person is a prison and also a recess' - Actual Author: Nietzsche, Predicted Author: Nietzsche\nSentence: ' every select man strives instinctively for a citadel and a privacy,\nwhere he is free from the crowd, the many, the majority--where he may\nforget \"men who are the rule,\" as their exception;--exclusive only of\nthe case in which he is pushed straight to such men by a still stronger\ninstinct, as a discerner in the great and exceptional sense' - Actual Author: Nietzsche, Predicted Author: Nietzsche\nSentence: '\nthe one all-embracing time, like the one all-embracing space, is a\nconstruction; there is no  direct  time-relation between particulars\nbelonging to my perspective and particulars belonging to another\nman's' - Actual Author: Russell, Predicted Author: Russell\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<span style=\"color:red\"> INSERT AN INTERPRETATION OF YOUR RESULTS HERE </span>","metadata":{"id":"2G3tlvHB_Hdw"}},{"cell_type":"markdown","source":"\nThe logistic regression model achieved high accuracy on the training set (96.3%) but slightly lower accuracy on the test set (83.2%). Here's an interpretation of the results:\n\nTraining Accuracy: The high training accuracy indicates that the model fits the training data well and can effectively distinguish between sentences written by Russell and Nietzsche based on the bag-of-words representations and sentence sentiments.\n\nTest Accuracy: The test accuracy is slightly lower than the training accuracy, suggesting that the model might be overfitting to some extent. However, the test accuracy is still relatively high, indicating that the model generalizes reasonably well to unseen data.\n\nIndividual Predictions:\nThe first two sentences were correctly predicted as Russell's, matching the actual authors.\nThe third sentence was correctly predicted as Nietzsche's.\nThe fourth sentence, originally written by Russell, was incorrectly predicted as Nietzsche's.\nThe fifth sentence, originally written by Nietzsche, was correctly predicted as Nietzsche's.\n\nInterpretation: Overall, the model performs well in identifying the authors of the sentences. However, there are instances where it misclassifies sentences, indicating that there might be some ambiguity in the writing styles of Russell and Nietzsche or that certain sentences share similarities in terms of sentiment and vocabulary. The misclassification of some sentences could also be attributed to the limited amount of data or noise in the training set. Further analysis and refinement of the model could potentially improve its performance.","metadata":{}}]}